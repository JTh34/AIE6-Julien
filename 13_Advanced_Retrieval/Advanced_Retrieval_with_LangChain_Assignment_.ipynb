{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-16 11:45:33--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 2606:50c0:8001::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
            "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443… connecté.\n",
            "requête HTTP transmise, en attente de la réponse… 200 OK\n",
            "Taille : 19628 (19K) [text/plain]\n",
            "Sauvegarde en : « john_wick_1.csv »\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19,17K  --.-KB/s    ds 0,005s  \n",
            "\n",
            "2025-05-16 11:45:33 (3,60 MB/s) — « john_wick_1.csv » sauvegardé [19628/19628]\n",
            "\n",
            "--2025-05-16 11:45:33--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
            "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443… connecté.\n",
            "requête HTTP transmise, en attente de la réponse… 200 OK\n",
            "Taille : 14747 (14K) [text/plain]\n",
            "Sauvegarde en : « john_wick_2.csv »\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14,40K  --.-KB/s    ds 0,002s  \n",
            "\n",
            "2025-05-16 11:45:34 (6,24 MB/s) — « john_wick_2.csv » sauvegardé [14747/14747]\n",
            "\n",
            "--2025-05-16 11:45:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
            "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443… connecté.\n",
            "requête HTTP transmise, en attente de la réponse… 200 OK\n",
            "Taille : 13888 (14K) [text/plain]\n",
            "Sauvegarde en : « john_wick_3.csv »\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13,56K  --.-KB/s    ds 0,004s  \n",
            "\n",
            "2025-05-16 11:45:34 (3,20 MB/s) — « john_wick_3.csv » sauvegardé [13888/13888]\n",
            "\n",
            "--2025-05-16 11:45:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Résolution de raw.githubusercontent.com (raw.githubusercontent.com)… 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
            "Connexion à raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443… connecté.\n",
            "requête HTTP transmise, en attente de la réponse… 200 OK\n",
            "Taille : 15109 (15K) [text/plain]\n",
            "Sauvegarde en : « john_wick_4.csv »\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14,75K  --.-KB/s    ds 0,004s  \n",
            "\n",
            "2025-05-16 11:45:35 (3,48 MB/s) — « john_wick_4.csv » sauvegardé [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23 May 2023</td>\n",
              "      <td>siderite</td>\n",
              "      <td>4.0</td>\n",
              "      <td>What a pointless film\\n</td>\n",
              "      <td>Imagine a video game where you are shooting ba...</td>\n",
              "      <td>/review/rw9073117/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30 March 2023</td>\n",
              "      <td>neil-476</td>\n",
              "      <td>5.0</td>\n",
              "      <td>There is such a thing as too much\\n</td>\n",
              "      <td>The Table, the international crminal brotherho...</td>\n",
              "      <td>/review/rw8960544/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25 March 2023</td>\n",
              "      <td>BA_Harrison</td>\n",
              "      <td>4.0</td>\n",
              "      <td>It got on my wick.\\n</td>\n",
              "      <td>The first three John Wick films came in fairly...</td>\n",
              "      <td>/review/rw8950606/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23 May 2023</td>\n",
              "      <td>namob-43673</td>\n",
              "      <td>3.0</td>\n",
              "      <td>I was rolling my eyes the whole time... all 3...</td>\n",
              "      <td>These John Wick movies can be sort of fun in t...</td>\n",
              "      <td>/review/rw9072963/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24 March 2023</td>\n",
              "      <td>fciocca</td>\n",
              "      <td>4.0</td>\n",
              "      <td>John Wick became the parody of himself. The t...</td>\n",
              "      <td>I went to the cinema with great expectations. ...</td>\n",
              "      <td>/review/rw8948738/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2 April 2023</td>\n",
              "      <td>skyhawk747</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Am I missing something here?\\n</td>\n",
              "      <td>What is all the raving about with this movie? ...</td>\n",
              "      <td>/review/rw8967740/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>24 March 2023</td>\n",
              "      <td>IMDbKeepsDeletingMyReviews</td>\n",
              "      <td>5.0</td>\n",
              "      <td>\"Yeah.\"\\n</td>\n",
              "      <td>In this fourth installment of 8711's successfu...</td>\n",
              "      <td>/review/rw8947952/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>23 April 2023</td>\n",
              "      <td>antti-eskelinen-329-929792</td>\n",
              "      <td>4.0</td>\n",
              "      <td>I don't understand the great scores of this m...</td>\n",
              "      <td>In my opinion this is by far the worst movie o...</td>\n",
              "      <td>/review/rw9011753/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>28 May 2023</td>\n",
              "      <td>dstan-71445</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Disappointed.\\n</td>\n",
              "      <td>Very much over rated. Repetitive, tiring and i...</td>\n",
              "      <td>/review/rw9082993/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>30 March 2023</td>\n",
              "      <td>drjgardner</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Ridiculous, boring and pathetic...\\n</td>\n",
              "      <td>...all at the same time. This hybrid comic boo...</td>\n",
              "      <td>/review/rw8959398/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22 March 2023</td>\n",
              "      <td>lovemichaeljordan</td>\n",
              "      <td>8.0</td>\n",
              "      <td>How Can Anyone Choose to Watch Marvel Over Th...</td>\n",
              "      <td>Most American action flicks released these day...</td>\n",
              "      <td>/review/rw8944843/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26 April 2023</td>\n",
              "      <td>kskmah</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NOPE\\n</td>\n",
              "      <td>Who needs a 2hr and 40 min action movie? No on...</td>\n",
              "      <td>/review/rw9017658/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>24 March 2023</td>\n",
              "      <td>FeastMode</td>\n",
              "      <td>9.0</td>\n",
              "      <td>A new standard has been set for fight scenes\\n</td>\n",
              "      <td>Half of this review will be me gushing about t...</td>\n",
              "      <td>/review/rw8947764/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>29 March 2023</td>\n",
              "      <td>MovieIQTest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Where is the STORY? A brainless video game?\\n</td>\n",
              "      <td>From the very beginning to the end, nothing bu...</td>\n",
              "      <td>/review/rw8957575/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>23 March 2023</td>\n",
              "      <td>markvanwasbeek</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Yeah\\n</td>\n",
              "      <td>By now you know what to expect from a John Wic...</td>\n",
              "      <td>/review/rw8946621/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5 April 2023</td>\n",
              "      <td>rupali-38827</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Damp Wick\\n</td>\n",
              "      <td>No idea how the ratings are as high as they ar...</td>\n",
              "      <td>/review/rw8972614/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>25 March 2023</td>\n",
              "      <td>vengeance20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>John Weak 4: It Loses It Way\\n</td>\n",
              "      <td>Ok, so I got back from seeing this entry yeste...</td>\n",
              "      <td>/review/rw8949045/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16 March 2023</td>\n",
              "      <td>tresm87</td>\n",
              "      <td>9.0</td>\n",
              "      <td>While the Wick franchise has already solidifi...</td>\n",
              "      <td>Stuntman turned writer/director Chad Stahelski...</td>\n",
              "      <td>/review/rw8932278/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17 March 2023</td>\n",
              "      <td>cadillac20</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Not Just The Best John Wick, But Possibly One...</td>\n",
              "      <td>Ever since the original John Wick, the franchi...</td>\n",
              "      <td>/review/rw8935367/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>17 March 2023</td>\n",
              "      <td>tkdlifemagazine</td>\n",
              "      <td>9.0</td>\n",
              "      <td>The Best John Wick Sequel\\n</td>\n",
              "      <td>John Wick: Chapter 4 picks up where Chapter 3:...</td>\n",
              "      <td>/review/rw8935117/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>23 March 2023</td>\n",
              "      <td>jtindahouse</td>\n",
              "      <td>9.0</td>\n",
              "      <td>THIS is how you justify a 3 hour runtime\\n</td>\n",
              "      <td>In a world where movie sequels seem to be loat...</td>\n",
              "      <td>/review/rw8946038/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>27 May 2023</td>\n",
              "      <td>leftbanker-1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Itchy and Scratchy: The Movie...again and aga...</td>\n",
              "      <td>He fights and bites, he fights and bites and f...</td>\n",
              "      <td>/review/rw9081081/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>25 March 2023</td>\n",
              "      <td>solidabs</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Horrible\\n</td>\n",
              "      <td>HORRIBLE movie. I love John Wick. I mean I wou...</td>\n",
              "      <td>/review/rw8949493/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>27 March 2023</td>\n",
              "      <td>statuskuo</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Sound And Fury Adds Up To Nothing\\n</td>\n",
              "      <td>Sitting through the nearly 3 hours of this opu...</td>\n",
              "      <td>/review/rw8954612/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3 June 2023</td>\n",
              "      <td>Phil_H</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Almost 3 hours of nothing\\n</td>\n",
              "      <td>John Wick: Chapter 4 is almost three hours of ...</td>\n",
              "      <td>/review/rw9097584/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Review_Date                      Author  Rating  \\\n",
              "0     23 May 2023                    siderite     4.0   \n",
              "1   30 March 2023                    neil-476     5.0   \n",
              "2   25 March 2023                 BA_Harrison     4.0   \n",
              "3     23 May 2023                 namob-43673     3.0   \n",
              "4   24 March 2023                     fciocca     4.0   \n",
              "5    2 April 2023                  skyhawk747     4.0   \n",
              "6   24 March 2023  IMDbKeepsDeletingMyReviews     5.0   \n",
              "7   23 April 2023  antti-eskelinen-329-929792     4.0   \n",
              "8     28 May 2023                 dstan-71445     2.0   \n",
              "9   30 March 2023                  drjgardner     2.0   \n",
              "10  22 March 2023           lovemichaeljordan     8.0   \n",
              "11  26 April 2023                      kskmah     1.0   \n",
              "12  24 March 2023                   FeastMode     9.0   \n",
              "13  29 March 2023                 MovieIQTest     NaN   \n",
              "14  23 March 2023              markvanwasbeek     9.0   \n",
              "15   5 April 2023                rupali-38827     4.0   \n",
              "16  25 March 2023                 vengeance20     4.0   \n",
              "17  16 March 2023                     tresm87     9.0   \n",
              "18  17 March 2023                  cadillac20    10.0   \n",
              "19  17 March 2023             tkdlifemagazine     9.0   \n",
              "20  23 March 2023                 jtindahouse     9.0   \n",
              "21    27 May 2023                leftbanker-1     1.0   \n",
              "22  25 March 2023                    solidabs     1.0   \n",
              "23  27 March 2023                   statuskuo     4.0   \n",
              "24    3 June 2023                      Phil_H     4.0   \n",
              "\n",
              "                                         Review_Title  \\\n",
              "0                             What a pointless film\\n   \n",
              "1                 There is such a thing as too much\\n   \n",
              "2                                It got on my wick.\\n   \n",
              "3    I was rolling my eyes the whole time... all 3...   \n",
              "4    John Wick became the parody of himself. The t...   \n",
              "5                      Am I missing something here?\\n   \n",
              "6                                           \"Yeah.\"\\n   \n",
              "7    I don't understand the great scores of this m...   \n",
              "8                                     Disappointed.\\n   \n",
              "9                Ridiculous, boring and pathetic...\\n   \n",
              "10   How Can Anyone Choose to Watch Marvel Over Th...   \n",
              "11                                             NOPE\\n   \n",
              "12     A new standard has been set for fight scenes\\n   \n",
              "13      Where is the STORY? A brainless video game?\\n   \n",
              "14                                             Yeah\\n   \n",
              "15                                        Damp Wick\\n   \n",
              "16                     John Weak 4: It Loses It Way\\n   \n",
              "17   While the Wick franchise has already solidifi...   \n",
              "18   Not Just The Best John Wick, But Possibly One...   \n",
              "19                        The Best John Wick Sequel\\n   \n",
              "20         THIS is how you justify a 3 hour runtime\\n   \n",
              "21   Itchy and Scratchy: The Movie...again and aga...   \n",
              "22                                         Horrible\\n   \n",
              "23                Sound And Fury Adds Up To Nothing\\n   \n",
              "24                        Almost 3 hours of nothing\\n   \n",
              "\n",
              "                                               Review  \\\n",
              "0   Imagine a video game where you are shooting ba...   \n",
              "1   The Table, the international crminal brotherho...   \n",
              "2   The first three John Wick films came in fairly...   \n",
              "3   These John Wick movies can be sort of fun in t...   \n",
              "4   I went to the cinema with great expectations. ...   \n",
              "5   What is all the raving about with this movie? ...   \n",
              "6   In this fourth installment of 8711's successfu...   \n",
              "7   In my opinion this is by far the worst movie o...   \n",
              "8   Very much over rated. Repetitive, tiring and i...   \n",
              "9   ...all at the same time. This hybrid comic boo...   \n",
              "10  Most American action flicks released these day...   \n",
              "11  Who needs a 2hr and 40 min action movie? No on...   \n",
              "12  Half of this review will be me gushing about t...   \n",
              "13  From the very beginning to the end, nothing bu...   \n",
              "14  By now you know what to expect from a John Wic...   \n",
              "15  No idea how the ratings are as high as they ar...   \n",
              "16  Ok, so I got back from seeing this entry yeste...   \n",
              "17  Stuntman turned writer/director Chad Stahelski...   \n",
              "18  Ever since the original John Wick, the franchi...   \n",
              "19  John Wick: Chapter 4 picks up where Chapter 3:...   \n",
              "20  In a world where movie sequels seem to be loat...   \n",
              "21  He fights and bites, he fights and bites and f...   \n",
              "22  HORRIBLE movie. I love John Wick. I mean I wou...   \n",
              "23  Sitting through the nearly 3 hours of this opu...   \n",
              "24  John Wick: Chapter 4 is almost three hours of ...   \n",
              "\n",
              "                        Review_Url  \n",
              "0   /review/rw9073117/?ref_=tt_urv  \n",
              "1   /review/rw8960544/?ref_=tt_urv  \n",
              "2   /review/rw8950606/?ref_=tt_urv  \n",
              "3   /review/rw9072963/?ref_=tt_urv  \n",
              "4   /review/rw8948738/?ref_=tt_urv  \n",
              "5   /review/rw8967740/?ref_=tt_urv  \n",
              "6   /review/rw8947952/?ref_=tt_urv  \n",
              "7   /review/rw9011753/?ref_=tt_urv  \n",
              "8   /review/rw9082993/?ref_=tt_urv  \n",
              "9   /review/rw8959398/?ref_=tt_urv  \n",
              "10  /review/rw8944843/?ref_=tt_urv  \n",
              "11  /review/rw9017658/?ref_=tt_urv  \n",
              "12  /review/rw8947764/?ref_=tt_urv  \n",
              "13  /review/rw8957575/?ref_=tt_urv  \n",
              "14  /review/rw8946621/?ref_=tt_urv  \n",
              "15  /review/rw8972614/?ref_=tt_urv  \n",
              "16  /review/rw8949045/?ref_=tt_urv  \n",
              "17  /review/rw8932278/?ref_=tt_urv  \n",
              "18  /review/rw8935367/?ref_=tt_urv  \n",
              "19  /review/rw8935117/?ref_=tt_urv  \n",
              "20  /review/rw8946038/?ref_=tt_urv  \n",
              "21  /review/rw9081081/?ref_=tt_urv  \n",
              "22  /review/rw8949493/?ref_=tt_urv  \n",
              "23  /review/rw8954612/?ref_=tt_urv  \n",
              "24  /review/rw9097584/?ref_=tt_urv  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"john_wick_4.csv\", index_col= 0)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 13, 11, 45, 35, 658602)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. Many reviews gave high ratings such as 9 or 10 out of 10 and praised it as a stylish, fun, and impressive action film. Critics and viewers highlighted its exciting action sequences, Keanu Reeves' performance, and the stylish world-building. However, there were some mixed opinions, with a few reviewers giving it lower scores like 5 or 6, expressing some confusion or less enthusiasm. Overall, the dominant sentiment is positive, indicating that most people appreciated and enjoyed the film.\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': AIMessage(content='Based on the reviews provided, people generally liked John Wick. Several reviews rate the film highly, praising its action sequences, style, and entertainment value. For example, some reviews give it ratings of 9 or 10 out of 10 and describe it as a fun, stylish, and exciting action movie. However, there are also some mixed opinions, with a few reviewers rating it lower, around 5 or 6, indicating that not everyone was equally impressed. Overall, the majority of the reviews suggest that people generally enjoyed John Wick.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 3602, 'total_tokens': 3712, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3456}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_eede8f0d45', 'id': 'chatcmpl-BXly5xN8rJwk4pUXkjT7HMLzT7zD7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--44d157d0-1673-4bb6-96d7-3d2cf1505bed-0', usage_metadata={'input_tokens': 3602, 'output_tokens': 110, 'total_tokens': 3712, 'input_token_details': {'audio': 0, 'cache_read': 3456}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " 'context': [Document(metadata={'source': 'john_wick_1.csv', 'row': 9, 'Review_Date': '20 October 2014', 'Review_Title': \" The coolest action film you'll see all year\\n\", 'Review_Url': '/review/rw3107759/?ref_=tt_urv', 'Author': 'trublu215', 'Rating': 9, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658615', '_id': '5b346af57c944d58b266438a7ff7d597', '_collection_name': 'JohnWick'}, page_content=\": 9\\nReview: At first glance, John Wick sounds like a terrible film on paper but with the slickness of Keanu Reeves' performance as the titular character and the sheer brilliance in its action sequences, this marks the best action film of the year and one of the absolute best in the past decade. Following a brutal home invasion that leaves his beloved dog murdered by thugs from his past, John Wick vows revenge on the ones who have taken what he loves most. Like I said, on paper, this seems like a direct-to-DVD slopfest starring John Cena but as a film with Keanu Reeves as the lead, it marks the very welcomed return for Reeves to the genre. John Wick is insanely fun, violently brutal and an overall romp especially for those disappointed by The Expendables 3. John Wick is propelled by Tarantino-esque dialog mixed with the swagger of action stars from the 70s. Reeves literally emulates cool in this film and does it with such confidence, that we don't even doubt the character...even when he kills countless bad guys with extreme force in some utterly ridiculous and implausible situations. We don't doubt it for a minute. This is EXACTLY what you want out of an action film. It is briskly paced, brilliantly shot and meticulously choreographed and keeps you wanting more and more. The supporting cast filled with the likes of John Legiuzamo, Ian McShane, and Willen Dafoe also keeps this film very interesting. These guys don't play good guys, hell, John Wick by traditional standards would be a bad guy in any other film. Every character is more ruthless than the next and pushes John Wick to be more ruthless than they are, creating a very cool dynamic between the character and the plot regarding the idea of how far is too far? However, don't expect some revelation from John Wick regarding the morality of bad and evil. This film wants you entertained and does so with brute force, it never lets up, not even for a second. One scene in particular that will have your blood pumping is a showdown between thugs and Wick in a nightclub. This action sequence remains the best in the film and will have you grasping your theater seat because of the sheer intensity of it. Overall, John Wick is slick, violent fun that turns into a remarkable, surprising film that will catch you off guard. It is THAT good. I highly recommend this film to action buffs especially but I'm sure those who just like a good movie will love it as well.\"),\n",
              "  Document(metadata={'source': 'john_wick_1.csv', 'row': 20, 'Review_Date': '22 October 2014', 'Review_Title': ' Smoothest action film to come around in a long time\\n', 'Review_Url': '/review/rw3109271/?ref_=tt_urv', 'Author': 'IceSkateUpHill', 'Rating': 10, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658621', '_id': 'e328f408f63d4efeac386d346396f281', '_collection_name': 'JohnWick'}, page_content=\": 20\\nReview: John Wick is something special. It takes as much time setting up elaborate action sequences as it does the world with which it all takes place in. And what a world it is. It reminds me of Millers Crossing and it is cooler than any other recent attempt at noir. We are shown a criminal underworld where, if you are connected, many powerful people know who you are and show you respect. John Wick was connected but he got out. He is the rare killer who has found peace, and he is grateful for that peace. Some young kids steal that from him and he does what he does best, he wages a one man war against the Russian Mafia. It might sound like the film takes quite a leap but it all makes sense. The motives of John and the people who get in the way of his bullets are all very clear, even if it does come across as rather simple. That's the plot at it's most basic. Then there's the action. The film is directed by Reeve's stuntman from The Matrix, so this guy knows action. There are sequences that flow so smoothly it puts other action films and their quick cuts to shame. Keaunu moves so fluidly throughout the film and comes across as such a natural that the only disappointment is that we have not seen him like this before. Along the way are plenty of character actors, fans of The Matrix and The Wire will recognize a few people then there are more obvious ones like Ian McShane and Willem Dafoe. Everyone seems to be having a good time. That is another plus for this movie. It get's dark at times but overall it is quite fun, not very chipper, but fun. I cannot recommend this movie enough. I believe it is a must see for action fans and for anyone looking for something a bit different from the usual fare.\"),\n",
              "  Document(metadata={'source': 'john_wick_3.csv', 'row': 5, 'Review_Date': '17 July 2019', 'Review_Title': ' The magic is gone\\n', 'Review_Url': '/review/rw4999970/?ref_=tt_urv', 'Author': 'soundoflight', 'Rating': 5, 'Movie_Title': 'John Wick 3', 'last_accessed_at': '2025-05-15T11:45:35.658921', '_id': '3e5ffb6c0c4a464a87773057b6417d9b', '_collection_name': 'JohnWick'}, page_content=': 5\\nReview: The first John Wick film was special because it broke a mold of sorts. It went against certain action film conventions - the hero was not a muscle bound hulk like a Schwarzenegger or Stallone, the action was super fast paced, the plot was basic and straighforward, but introduced some unique elements, and there was something a bit unique and stylish about the film. John Wick was cool.'),\n",
              "  Document(metadata={'source': 'john_wick_4.csv', 'row': 14, 'Review_Date': '23 March 2023', 'Review_Title': ' Yeah\\n', 'Review_Url': '/review/rw8946621/?ref_=tt_urv', 'Author': 'markvanwasbeek', 'Rating': 9, 'Movie_Title': 'John Wick 4', 'last_accessed_at': '2025-05-16T11:45:35.659069', '_id': 'ecdb1eb8c2514865a9cee8b39d4eb4cd', '_collection_name': 'JohnWick'}, page_content=\": 14\\nReview: By now you know what to expect from a John Wick movie. I thought the franchise was losing a little momentum in chapter 3 so I was worried this could be disappointing. It's not. It's even more on steroids than any Wick before! Even close to 3 hours it doesn't feel to long which is very special for a action movie. This franchise has set new standards. If anybody says a movie is good like John Wick, it better f'n be! The set pieces as everyone mentioned before are really insane this time. The Tokyo sceney with illuminated cherry blossoms was beautiful. The only super illogical thing that bothered me was that nobody flinched at the nightclub, eventually they did but after a whole 10 minute beatdown through the whole club, but then again it's a shady nightclub for high table people. If you liked the first three movies, get your ass to the cinema. Yeah.\"),\n",
              "  Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658602', '_id': '7b82358906064888b31a0acbdc3970ce', '_collection_name': 'JohnWick'}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\"),\n",
              "  Document(metadata={'source': 'john_wick_2.csv', 'row': 6, 'Review_Date': '14 February 2017', 'Review_Title': \" John Wick: Chapter 2 continues it's faced paced, neo-noir story of our assassin\\n\", 'Review_Url': '/review/rw3639868/?ref_=tt_urv', 'Author': 'RforFilm', 'Rating': 8, 'Movie_Title': 'John Wick 2', 'last_accessed_at': '2025-05-14T11:45:35.658773', '_id': '570ac8de6c4c4701821a19d2c4e3829f', '_collection_name': 'JohnWick'}, page_content=\": 6\\nReview: In 2014, a Keanu Reeves revenge thriller John Wick became a surprise hit. I originally skipped out on the film as I felt that the trailers only showed an assassin story that I felt I've seen before. As far as I'm concerned, I made a big mistake. Before seeing the sequel, I felt it was important to watch the first one. I rented it on Amazon Prime and I was shock by what I saw; a dark, stylish, and fun action movie that is doing it's own thing. Though I've seen plenty stories about revenge (The Count of Monte Cristo and Moby Dick being the prime examples), I can't recall one over someone's pet being murdered.\"),\n",
              "  Document(metadata={'source': 'john_wick_4.csv', 'row': 20, 'Review_Date': '23 March 2023', 'Review_Title': ' THIS is how you justify a 3 hour runtime\\n', 'Review_Url': '/review/rw8946038/?ref_=tt_urv', 'Author': 'jtindahouse', 'Rating': 9, 'Movie_Title': 'John Wick 4', 'last_accessed_at': '2025-05-16T11:45:35.659071', '_id': 'b64c2acf23264d4f90560b93e58b0e44', '_collection_name': 'JohnWick'}, page_content=\": 20\\nReview: In a world where movie sequels seem to be loathed even before they are released, the 'John Wick' series has remained remarkably consistent and well received. In fact all three of the first films have the same IMDb rating of 7.4/10 and I noticed recently that I gave them all the same rating of 8/10. Incredibly, I think 'John Wick: Chapter 4' is the best the series has to offer. This movie was a wild ride.\"),\n",
              "  Document(metadata={'source': 'john_wick_1.csv', 'row': 2, 'Review_Date': '5 May 2023', 'Review_Title': \" You don't mess with another person's dog. It's as simple as that!\\n\", 'Review_Url': '/review/rw9033669/?ref_=tt_urv', 'Author': 'Coventry', 'Rating': 5, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658611', '_id': '9537b284f72b43ea963812a56bcf9cb9', '_collection_name': 'JohnWick'}, page_content=': 2\\nReview: With the fourth installment scoring immensely at the cinemas as I\\'m submitting this review, and after three previous films that are apparently loved by everyone else in the world, I thought perhaps it would be time for me check out \"John Wick\".'),\n",
              "  Document(metadata={'source': 'john_wick_1.csv', 'row': 5, 'Review_Date': '23 March 2023', 'Review_Title': ' Violent and gripping story with plenty of unstopped action , shootouts and breathtaking fights\\n', 'Review_Url': '/review/rw8945545/?ref_=tt_urv', 'Author': 'ma-cortes', 'Rating': 7, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658613', '_id': '7235f0022719435b806b5f17e893fd2f', '_collection_name': 'JohnWick'}, page_content=\": 5\\nReview: Ultra-violent first entry with lots of killings, thrills , noisy action , suspense , and crossfire . In this original John Wick (2014) , an ex-hit-man comes out of retirement to track down the gangsters that killed his dog and took everything from him . With the untimely death of his beloved wife still bitter in his mouth he seeks for vengeance . But when an arrogant Russian mob prince and hoodlums steal his car and kill his dog , they are fully aware of his lethal capacity. The Bogeyman will find himself dragged into an impossible task as every killer in the business dreams of cornering the legendary Wick who now has an enormous price on his head . In this first installment John Wick , blind with revenge, and for his salvation John will immediately unleash a carefully orchestrated maelstrom of destruction against those attempt to chase him and with a price tag on his head, as he is the target of hit men : an army of bounty-hunting killers on his trail and a murderer woman everywhere . The legendary hitman will be forced to unearth his meticulously concealed identity and to carry out a relentless vendetta . Now, only blood can quench the boogeyman's thirst for retribution . Don't Set Him Off! . John Wick isn't the Boogeyman... He's the guy you send to kill the doomed Boogeyman. Revenge is all he has left. You want peace, prepare for war . Don't Hunt What You Can't Kill. Tick Tock, Mr. Wick. Everyone Is Waiting. For John Wick . Every Action Has Consequences. This Friday, Wick is Back . Its the World Vs. Wick. Every Action Has Consequences.\"),\n",
              "  Document(metadata={'source': 'john_wick_1.csv', 'row': 19, 'Review_Date': '14 April 2023', 'Review_Title': \" I Don't Get It\\n\", 'Review_Url': '/review/rw8991670/?ref_=tt_urv', 'Author': 'xiaoli7377', 'Rating': 6, 'Movie_Title': 'John Wick 1', 'last_accessed_at': '2025-05-13T11:45:35.658620', '_id': 'fe380eec73334174a5fa5457689dec13', '_collection_name': 'JohnWick'}, page_content=': 19\\nReview: I really don\\'t understand the love that \"John Wick\" receives. It\\'s just kind of a generic action thriller to me. No different than a \"Bourne\" or \"Taken\" movie. It gets a slight bump for me in a rating of 6 instead of 5 because I did think that the cinematography was really good and also the fight choreography was top notch. I can definitely see the influence of martial arts films on this.')]}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n1. /review/rw4854296/?ref_=tt_urv\\n2. /review/rw8944843/?ref_=tt_urv'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the \"John Wick\" series, the story centers around John Wick, a retired hitman who seeks revenge after his dog is killed, and his car is stolen, both of which are considered personal and significant losses. The first film depicts his emergence from retirement to target the gangsters responsible, unleashing a relentless and violent rampage. Throughout the series, Wick faces various enemies within the criminal underworld, including Russian mobsters, assassins, and mob bosses, often challenging the strict rules of the assassin community. The series explores his quest for vengeance, survival, and often delves into his complex past as a legendary assassin. The movies are known for their stylish, choreographed action sequences and dark, noir-like world of crime and retribution.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided reviews, people\\'s opinions on John Wick vary. Some reviews are highly positive, praising the movies for their stylish action, engaging world-building, and fun excitement, especially for the first film and the second one. For example, one reviewer gave the first film a 10 out of 10 and called it \"something special,\" praising its action sequences and world. However, other reviews are negative, particularly for the third and fourth films, describing them as dull, boring, overly violent, and lacking plot. One reviewer rated the third film a 1 out of 10 and criticized it for being mindless and plotless.\\n\\nOverall, while many fans enjoy John Wick for its action and style, there are also strong negative opinions about certain installments. Therefore, it can be said that people\\'s opinions about John Wick are mixed, with a significant number of viewers liking it, especially for its earlier movies.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There are no reviews with a rating of 10 in the provided data.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the \"John Wick\" film series, the story centers around John Wick, a former assassin who is pulled back into the violent underworld he thought he left behind. The movies depict his fight for survival against numerous assassins and powerful organizations, often driven by personal loss, revenge, or the need to protect himself. The series is known for its beautifully choreographed action scenes, intense fight sequences, and the intricate criminal society that governs the assassins.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews, people generally liked John Wick. The first two reviews are highly positive, praising it as an excellent action film with a high rating of 9 and 10 out of 10, respectively. The third review, of John Wick 3, is more mixed with a moderate rating of 5 out of 10, indicating some disappointment with that installment. Overall, the reception suggests that audiences appreciated the film, especially for its action, style, and performance, though opinions on subsequent installments vary.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. [John Wick 3 Review](https://example.com/review/rw4854296/?ref_=tt_urv)\\n2. [John Wick 4 Review](https://example.com/review/rw8944843/?ref_=tt_urv)\\n\\n(Note: The actual URLs are provided in the context as relative paths. You can access them directly from the review details.)'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick series, John Wick, a retired hitman played by Keanu Reeves, seeks revenge after personal tragedies. In the first film, his wife dies, and someone steals his car and kills his dog, which was a gift from his wife. These events pull him back into the violent world he had left behind, leading him to hunt down those responsible. The story involves him confronting Russian gangsters, dealing with his past as a legendary assassin, and unearthing a larger criminal underworld. \\n\\nIn the second film, John Wick is drawn into a new conflict when a criminal from his past, Santino D'Antonio, seeks his help to eliminate his sister so he can sit on the High Table. Wick refuses but is later forced to comply, which results in a series of violent repercussions. Santino betrays him, blowing up Wick's house, and puts a bounty on his head, making him a target for killers worldwide. Wick's storyline revolves around themes of revenge, loyalty, and navigating the rules of the criminal underworld.\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. Many reviews rate the first film highly, praising its stylish action sequences, Keanu Reeves' performance, and its fun, revenge-driven plot. Review scores like 9 or 10 out of 10 indicate strong positive reception. However, opinions on subsequent films vary, with some reviewers feeling the later installments become overly frenetic, over-the-top, or lose some of their initial appeal. Nonetheless, overall, the series is viewed favorably by many action fans and is considered a successful and entertaining franchise.\""
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick film series, the story centers around John Wick, a retired assassin who comes out of retirement after a series of personal tragedies and provocations. The first movie begins with Wick seeking revenge after gangsters kill his dog and steal his car, which leads him to unleash a violent rampage against those who cross him, revealing his formidable skills and a dark world of international assassins. The sequels expand on this universe, exploring Wick's conflicts with criminal organizations, his quest for peace, and the consequences of his violent past. Throughout the series, John Wick is depicted as a highly skilled and relentless hitman navigating a brutal underworld.\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/8h/kl800c1j6hjc9xt9lm_1bhph0000gn/T/ipykernel_17125/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided reviews, people generally liked John Wick. Many reviews praise the action, choreography, and overall quality of the series. While there is at least one negative review for John Wick 4, the majority of reviews reflect positive opinions about the series.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL for that review is /review/rw4854296/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick movies, John Wick is a retired assassin who is drawn back into a violent world of killing and revenge. In the first film, he comes out of retirement after a gang kills his dog and steals his car, unleashing a destructive rampage against those responsible. The plot revolves around his quest for vengeance and his lethal skills. In the second movie, he is called back into action to help someone take over the Assassin's Guild, which involves traveling to Italy, Canada, and Manhattan and engaging in numerous violent confrontations with other assassins. Overall, the series features intense action, killings, and John's struggle with his past and the consequences of violence.\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews in the provided context, people generally liked John Wick. Several reviews gave high ratings (e.g., 9 or 10 out of 10) and described the film as stylish, fun, and a must-see for action fans. Many reviewers praised the action sequences, Keanu Reeves' performance, and the unique style of the movies. Although there are some critical opinions and lower ratings, the overall sentiment appears to be positive with a strong appreciation for the series' action and style.\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n- /review/rw4854296/?ref_=tt_urv\\n- /review/rw4860412/?ref_=tt_urv'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick film series, the story follows John Wick, a retired but legendary assassin, who is drawn back into the violent underworld of hitmen and criminals after personal tragedies and provocations. The first film depicts his quest for revenge after a gang steals his car and kills his dog, leading him to unleash a brutal and highly choreographed rampage against those responsible. Subsequent films expand on his past, his connections with the assassin's guild, and the consequences of his actions, with ongoing themes of vengeance, loyalty, and the dark world of organized crime. Throughout the series, Wick navigates a dangerous landscape filled with professional killers, rules of the underworld, and relentless enemies, often with high-stakes action sequences and a complex buildup of the criminal universe he is part of.\""
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. The majority of reviews are highly positive, praising its action sequences, style, and entertainment value. Some reviews even mention that the series has remained well-received and popular among audiences.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. \\n\\nThe URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the movie John Wick, the story follows a retired assassin named John Wick (played by Keanu Reeves) who is drawn back into the world of violence and revenge after a series of tragic events. A group of thugs break into his house, beat him up, kill his beloved dog, and steal his car—actions that ignite John Wick's desire for vengeance. The film centers on his relentless quest to hunt down those responsible, confronting a dangerous underworld filled with gangsters, hitmen, and assassins. The plot explores themes of loss, retribution, and the consequences of violence, all set against a backdrop of stylish and intense action sequences.\""
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from ragas.testset import TestsetGenerator\n",
        "from ragas import EvaluationDataset\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "from ragas import EvaluationDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import osa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Imports LangChain\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.callbacks.tracers import LangChainTracer\n",
        "from langchain.schema.runnable import RunnableConfig\n",
        "\n",
        "# Imports LangSmith\n",
        "from langsmith import Client, traceable\n",
        "from langsmith.run_helpers import get_current_run_tree\n",
        "\n",
        "# Imports RAGAS\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.testset import TestsetGenerator\n",
        "from ragas import EvaluationDataset\n",
        "from ragas.metrics import (\n",
        "    LLMContextRecall,\n",
        "    Faithfulness,\n",
        "    FactualCorrectness,\n",
        "    ResponseRelevancy,\n",
        "    ContextEntityRecall,\n",
        "    NoiseSensitivity\n",
        ")\n",
        "from ragas import evaluate, RunConfig\n",
        "# Import required libraries\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from langsmith import Client\n",
        "from langchain_core.tracers import LangChainTracer\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from operator import itemgetter\n",
        "from copy import deepcopy\n",
        "import uuid\n",
        "from ragas.metrics import (\n",
        "    LLMContextRecall,\n",
        "    Faithfulness,\n",
        "    FactualCorrectness,\n",
        "    ResponseRelevancy,\n",
        "    ContextEntityRecall\n",
        ")\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.run_config import RunConfig\n",
        "from ragas import EvaluationDataset\n",
        "from langchain_openai import ChatOpenAI\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa58242c169247c58611b498df227ae6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5f5ad9adc454c7eb80c89fe4af3f49f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node b0746b26-7cc6-4926-80d7-82bcfc2e342b does not have a summary. Skipping filtering.\n",
            "Node bb137e6e-bad7-4415-a7ca-4bf6fbb4460c does not have a summary. Skipping filtering.\n",
            "Node 7b753263-1d74-4a7a-b13e-b152b7c5f26c does not have a summary. Skipping filtering.\n",
            "Node db9288c5-e46f-47ef-94e6-bd53d0b845de does not have a summary. Skipping filtering.\n",
            "Node b26f4532-ea45-4744-a935-a321079fb4ba does not have a summary. Skipping filtering.\n",
            "Node f3642c6a-fb69-4671-a623-8b28c98bca9a does not have a summary. Skipping filtering.\n",
            "Node 70d1b748-0a63-4006-857a-be28de5d91c9 does not have a summary. Skipping filtering.\n",
            "Node 23005360-70d6-44db-b54f-e8754d28b597 does not have a summary. Skipping filtering.\n",
            "Node 007285c0-9f2f-4e35-8be6-60a6f655c632 does not have a summary. Skipping filtering.\n",
            "Node a8f1c2e7-0d45-4a9b-ac6a-aa92da0c886c does not have a summary. Skipping filtering.\n",
            "Node 698bdffb-7f5c-48ec-b92f-073e15000dc9 does not have a summary. Skipping filtering.\n",
            "Node 0d5075da-a3bc-4142-80c4-eea6e40d74b7 does not have a summary. Skipping filtering.\n",
            "Node f9ec7756-7d6d-458c-a681-c356bfbc80fd does not have a summary. Skipping filtering.\n",
            "Node aa167f59-9208-4590-be27-8c97222315e5 does not have a summary. Skipping filtering.\n",
            "Node 1c2a3829-7e60-4f86-9aa6-8b833c5f8b72 does not have a summary. Skipping filtering.\n",
            "Node 9a1f16fc-0be1-4203-9925-39715e41488c does not have a summary. Skipping filtering.\n",
            "Node b3568578-301b-4ee1-aa06-cd2aef6e9107 does not have a summary. Skipping filtering.\n",
            "Node 48cd59cd-e89b-4396-9f8c-70cbec6ee592 does not have a summary. Skipping filtering.\n",
            "Node 4e2df0a3-f2ab-4104-afbe-cf5f36119871 does not have a summary. Skipping filtering.\n",
            "Node 34b870fa-a0fd-4c9a-a45a-cb85e9db68f3 does not have a summary. Skipping filtering.\n",
            "Node 6c6d0117-225a-4e3d-8331-821bee694514 does not have a summary. Skipping filtering.\n",
            "Node 34112e12-0168-40b2-bd1b-f1ad9ae085a7 does not have a summary. Skipping filtering.\n",
            "Node 5734f374-15ec-4dea-999f-37f265cbfb8d does not have a summary. Skipping filtering.\n",
            "Node e2007da6-deb4-4fa5-9d05-0526c8cd3ac4 does not have a summary. Skipping filtering.\n",
            "Node 85821bbf-0de3-474b-940a-66968638015d does not have a summary. Skipping filtering.\n",
            "Node 020627f5-9b89-4687-8960-298d01e8067e does not have a summary. Skipping filtering.\n",
            "Node d02a3893-9b90-4787-93eb-6be147bbc20e does not have a summary. Skipping filtering.\n",
            "Node 78e8ce98-3a43-4968-af91-c858e218f878 does not have a summary. Skipping filtering.\n",
            "Node 18c3b02d-587e-46d4-a377-4013af58a1cf does not have a summary. Skipping filtering.\n",
            "Node 859806dd-e90a-47a5-989a-f797855e988c does not have a summary. Skipping filtering.\n",
            "Node 1f76cfd7-3a35-4494-b4fa-4f83e772ebd5 does not have a summary. Skipping filtering.\n",
            "Node 60a01c19-d18a-4031-8d32-64c48b0ee362 does not have a summary. Skipping filtering.\n",
            "Node 23207935-d047-49b3-ac18-531ddb1649f3 does not have a summary. Skipping filtering.\n",
            "Node 98180426-8ec3-47c7-845e-418496f76611 does not have a summary. Skipping filtering.\n",
            "Node 2a77e01e-084d-4529-bd5f-be317a5c8d19 does not have a summary. Skipping filtering.\n",
            "Node c22adc45-86b5-4aac-bf76-951edea5c475 does not have a summary. Skipping filtering.\n",
            "Node 3ce390bb-77c5-4724-a426-98e7d3bdeeec does not have a summary. Skipping filtering.\n",
            "Node f5ce4a5a-f669-4645-967d-d5a58ce0e9e6 does not have a summary. Skipping filtering.\n",
            "Node bfbac003-3989-43fa-b8f7-4e8e42c2f1eb does not have a summary. Skipping filtering.\n",
            "Node b4e61f05-17b5-42db-9e60-b8c1bb39ae62 does not have a summary. Skipping filtering.\n",
            "Node 190c898a-13e7-4d1a-8e7b-76563ccc45bb does not have a summary. Skipping filtering.\n",
            "Node 0acfdf3d-8b93-458b-b542-0d4251069896 does not have a summary. Skipping filtering.\n",
            "Node c690383b-03d8-4683-8102-9a84ff3104e2 does not have a summary. Skipping filtering.\n",
            "Node e40b1a57-e7f7-4194-a703-5de837475c26 does not have a summary. Skipping filtering.\n",
            "Node 1d29ef52-0e05-477a-b603-eb8914d7653f does not have a summary. Skipping filtering.\n",
            "Node 54fdaa62-83da-41cc-895d-5e76f81cf437 does not have a summary. Skipping filtering.\n",
            "Node 844d28ec-cf74-479f-a9af-96326d1ff0a1 does not have a summary. Skipping filtering.\n",
            "Node 914b4ddb-bd62-4cb6-a230-bef594501cd0 does not have a summary. Skipping filtering.\n",
            "Node be617d86-67ad-435a-b945-e9f65836d874 does not have a summary. Skipping filtering.\n",
            "Node 55fc7240-1ffa-42c1-9810-a06886e9ca83 does not have a summary. Skipping filtering.\n",
            "Node 683e3dae-e066-4367-9b13-025b95e5f33f does not have a summary. Skipping filtering.\n",
            "Node b28e3a22-4783-4981-93e4-16fb5ba7f2ae does not have a summary. Skipping filtering.\n",
            "Node 03a5d9de-548e-4452-b14f-1bd23cec5820 does not have a summary. Skipping filtering.\n",
            "Node 00ff72a1-bb39-4f3a-a518-9068eacae7a9 does not have a summary. Skipping filtering.\n",
            "Node 019cdc92-c2ab-4ff2-84b2-2bf0b8c0b050 does not have a summary. Skipping filtering.\n",
            "Node ae51955d-daf7-4a92-9cd4-57bb1754569a does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5e2b8a7fd64abb94277c0ea6dfd785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7e0c76a0c194f07bbe735cd1c63dc9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f99dea46ff88407994088c6dac900752",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d85bd882a0fc41c68a5b6c9306266a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ef76e1f970344e8a536112ab629296e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate SDG\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "testset_dataset = generator.generate_with_langchain_docs(documents, testset_size=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does the movie John Wick compare to Taken ...</td>\n",
              "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
              "      <td>John Wick can be described as similar to Taken...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Considering the widespread acclaim and the suc...</td>\n",
              "      <td>[: 2\\nReview: With the fourth installment scor...</td>\n",
              "      <td>Given the immense success of the fourth instal...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why John Wick movie so special even if story j...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>John Wick has a very simple revenge story summ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why John Wick get mad at the Russian mobsters ...</td>\n",
              "      <td>[: 4\\nReview: Though he no longer has a taste ...</td>\n",
              "      <td>John Wick, a retired assassin, suffers a perso...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What aspects of Keanu Reeves' performance and ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 23\\nReview: Rating 10/10\\nI was ...</td>\n",
              "      <td>Keanu Reeves delivers an excellent acting perf...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>why john wick movie got so much over the top a...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 0\\nReview: No doubt about it, \"J...</td>\n",
              "      <td>The John Wick movies feature over the top acti...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the John Wick franchise's portrayal o...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 15\\nReview: ...totally over-rate...</td>\n",
              "      <td>The John Wick franchise initially set a high s...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do the film reviews reflect the themes of ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 18\\nReview: The first John Wick ...</td>\n",
              "      <td>The film reviews highlight a stark contrast be...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How do the critiques of Reeves' character in t...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 22\\nReview: All the below are no...</td>\n",
              "      <td>The first review criticizes Reeves' character ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does the Hollywood portrayal of action fil...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 11\\nReview: JOHN WICK is a rare ...</td>\n",
              "      <td>JOHN WICK is praised as a rare example of Holl...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the reviews of JOHN WICK 3 and John Wic...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 19\\nReview: The inevitable third...</td>\n",
              "      <td>The review of JOHN WICK 3 praises the film for...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does John Wick connect to The Matrix in te...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 7\\nReview: John Wick (2014) is t...</td>\n",
              "      <td>John Wick connects to The Matrix through Keanu...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   How does the movie John Wick compare to Taken ...   \n",
              "1   Considering the widespread acclaim and the suc...   \n",
              "2   Why John Wick movie so special even if story j...   \n",
              "3   Why John Wick get mad at the Russian mobsters ...   \n",
              "4   What aspects of Keanu Reeves' performance and ...   \n",
              "5   why john wick movie got so much over the top a...   \n",
              "6   How does the John Wick franchise's portrayal o...   \n",
              "7   How do the film reviews reflect the themes of ...   \n",
              "8   How do the critiques of Reeves' character in t...   \n",
              "9   How does the Hollywood portrayal of action fil...   \n",
              "10  How do the reviews of JOHN WICK 3 and John Wic...   \n",
              "11  How does John Wick connect to The Matrix in te...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [: 0\\nReview: The best way I can describe John...   \n",
              "1   [: 2\\nReview: With the fourth installment scor...   \n",
              "2   [: 3\\nReview: John wick has a very simple reve...   \n",
              "3   [: 4\\nReview: Though he no longer has a taste ...   \n",
              "4   [<1-hop>\\n\\n: 23\\nReview: Rating 10/10\\nI was ...   \n",
              "5   [<1-hop>\\n\\n: 0\\nReview: No doubt about it, \"J...   \n",
              "6   [<1-hop>\\n\\n: 15\\nReview: ...totally over-rate...   \n",
              "7   [<1-hop>\\n\\n: 18\\nReview: The first John Wick ...   \n",
              "8   [<1-hop>\\n\\n: 22\\nReview: All the below are no...   \n",
              "9   [<1-hop>\\n\\n: 11\\nReview: JOHN WICK is a rare ...   \n",
              "10  [<1-hop>\\n\\n: 19\\nReview: The inevitable third...   \n",
              "11  [<1-hop>\\n\\n: 7\\nReview: John Wick (2014) is t...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   John Wick can be described as similar to Taken...   \n",
              "1   Given the immense success of the fourth instal...   \n",
              "2   John Wick has a very simple revenge story summ...   \n",
              "3   John Wick, a retired assassin, suffers a perso...   \n",
              "4   Keanu Reeves delivers an excellent acting perf...   \n",
              "5   The John Wick movies feature over the top acti...   \n",
              "6   The John Wick franchise initially set a high s...   \n",
              "7   The film reviews highlight a stark contrast be...   \n",
              "8   The first review criticizes Reeves' character ...   \n",
              "9   JOHN WICK is praised as a rare example of Holl...   \n",
              "10  The review of JOHN WICK 3 praises the film for...   \n",
              "11  John Wick connects to The Matrix through Keanu...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset_df = testset_dataset.to_pandas()\n",
        "testset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "retrievers = [\n",
        "    {\"name\": \"Naive Retriever\", \"retriever\": naive_retriever},\n",
        "    {\"name\": \"BM25 Retriever\", \"retriever\": bm25_retriever},\n",
        "    {\"name\": \"Contextual Compression\", \"retriever\": compression_retriever},\n",
        "    {\"name\": \"Multi-Query Retriever\", \"retriever\": multi_query_retriever},\n",
        "    {\"name\": \"Parent Document Retriever\", \"retriever\": parent_document_retriever},\n",
        "    {\"name\": \"Ensemble Retriever\", \"retriever\": ensemble_retriever},\n",
        "    {\"name\": \"Semantic Chunking Retriever\", \"retriever\": semantic_retriever}\n",
        "]\n",
        "\n",
        "eval_llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_ragas_evaluation(updated_testsets, results_df, llm):\n",
        "\n",
        "    print(\"\\nRunning RAGAS evaluation...\")\n",
        "    \n",
        "    # Create a wrapper for the LLM for RAGAS\n",
        "    evaluator_llm = LangchainLLMWrapper(llm)\n",
        "    \n",
        "    # Configure RAGAS run parameters\n",
        "    run_config = RunConfig(\n",
        "        timeout=600,  \n",
        "        max_workers=2  \n",
        "    )\n",
        "    \n",
        "    # Define RAGAS metrics to evaluate\n",
        "    metrics = [\n",
        "        LLMContextRecall(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        ResponseRelevancy(),\n",
        "        ContextEntityRecall()\n",
        "    ]\n",
        "    \n",
        "    # Store RAGAS results for each retriever\n",
        "    ragas_results = {}\n",
        "    \n",
        "    # Get retrievers from results_df\n",
        "    retriever_names = results_df[\"Retriever\"].tolist()\n",
        "    \n",
        "    # Process each retriever separately to get RAGAS scores\n",
        "    for retriever_name in retriever_names:\n",
        "        print(f\"Running RAGAS evaluation for {retriever_name}...\")\n",
        "        \n",
        "        try:\n",
        "            # Get the updated testset for this retriever\n",
        "            retriever_testset = updated_testsets[retriever_name]\n",
        "            \n",
        "            # Convert the testset to a pandas DataFrame for RAGAS\n",
        "            df = retriever_testset.to_pandas()\n",
        "            \n",
        "            # Create a new DataFrame for RAGAS format\n",
        "            ragas_df = pd.DataFrame()\n",
        "            \n",
        "            # Map necessary columns from the testset format to RAGAS format\n",
        "            # RAGAS expects question, answer, contexts, and ground_truths\n",
        "            \n",
        "            # Get user inputs (questions)\n",
        "            if 'user_input' in df.columns:\n",
        "                ragas_df['question'] = df['user_input']\n",
        "            else:\n",
        "                # If the structure is nested\n",
        "                ragas_df['question'] = df.apply(\n",
        "                    lambda row: row['eval_sample']['user_input'] \n",
        "                    if isinstance(row['eval_sample'], dict) \n",
        "                    else row['eval_sample'].user_input,\n",
        "                    axis=1\n",
        "                )\n",
        "            \n",
        "            # Get responses (answers)\n",
        "            if 'response' in df.columns:\n",
        "                ragas_df['answer'] = df['response']\n",
        "            else:\n",
        "                # If the structure is nested\n",
        "                ragas_df['answer'] = df.apply(\n",
        "                    lambda row: row['eval_sample']['response'] \n",
        "                    if isinstance(row['eval_sample'], dict) \n",
        "                    else row['eval_sample'].response,\n",
        "                    axis=1\n",
        "                )\n",
        "            \n",
        "            # Get retrieved contexts\n",
        "            if 'retrieved_contexts' in df.columns:\n",
        "                ragas_df['contexts'] = df['retrieved_contexts'].apply(\n",
        "                    lambda x: x if isinstance(x, list) else [x]\n",
        "                )\n",
        "            else:\n",
        "                # If the structure is nested\n",
        "                ragas_df['contexts'] = df.apply(\n",
        "                    lambda row: row['eval_sample']['retrieved_contexts'] \n",
        "                    if isinstance(row['eval_sample'], dict) \n",
        "                    else row['eval_sample'].retrieved_contexts,\n",
        "                    axis=1\n",
        "                )\n",
        "            \n",
        "            # Ground truths (if available, otherwise use empty lists)\n",
        "            if 'ground_truth' in df.columns:\n",
        "                ragas_df['ground_truths'] = df['ground_truth'].apply(\n",
        "                    lambda x: x if isinstance(x, list) else [x]\n",
        "                )\n",
        "            else:\n",
        "                # For RAGAS evaluation without ground truths\n",
        "                ragas_df['ground_truths'] = [[] for _ in range(len(df))]\n",
        "            \n",
        "            # Convert to RAGAS EvaluationDataset\n",
        "            try:\n",
        "                evaluation_dataset = EvaluationDataset.from_pandas(ragas_df)\n",
        "                \n",
        "                # Run RAGAS evaluation\n",
        "                ragas_result = evaluate(\n",
        "                    dataset=evaluation_dataset,\n",
        "                    metrics=metrics,\n",
        "                    llm=evaluator_llm,\n",
        "                    run_config=run_config\n",
        "                )\n",
        "                \n",
        "                # Store the result\n",
        "                ragas_results[retriever_name] = ragas_result\n",
        "                \n",
        "                # Extract metric scores\n",
        "                llm_context_recall = np.mean(ragas_result.get('llm_context_recall', [0]))\n",
        "                faithfulness = np.mean(ragas_result.get('faithfulness', [0]))\n",
        "                factual_correctness = np.mean(ragas_result.get('factual_correctness(mode=f1)', [0]))\n",
        "                response_relevancy = np.mean(ragas_result.get('answer_relevancy', [0]))\n",
        "                context_entity_recall = np.mean(ragas_result.get('context_entity_recall', [0]))\n",
        "                \n",
        "                # Calculate overall quality score (average of all metrics)\n",
        "                quality_score = np.mean([\n",
        "                    llm_context_recall,\n",
        "                    faithfulness,\n",
        "                    factual_correctness,\n",
        "                    response_relevancy,\n",
        "                    context_entity_recall\n",
        "                ])\n",
        "                \n",
        "                # Update the quality score in results_df\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Quality Score\"] = quality_score\n",
        "                \n",
        "                # Store individual metrics\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"LLM Context Recall\"] = llm_context_recall\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Faithfulness\"] = faithfulness\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Factual Correctness\"] = factual_correctness\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Response Relevancy\"] = response_relevancy\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Context Entity Recall\"] = context_entity_recall\n",
        "                \n",
        "                print(f\"✓ RAGAS evaluation completed for {retriever_name}: Quality Score = {quality_score:.2f}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error in RAGAS dataset creation for {retriever_name}: {e}\")\n",
        "                results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Quality Score\"] = 0.5\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in RAGAS evaluation for {retriever_name}: {e}\")\n",
        "            # Use a placeholder score in case of errors\n",
        "            results_df.loc[results_df[\"Retriever\"] == retriever_name, \"Quality Score\"] = 0.5\n",
        "    \n",
        "    # Calculate efficiency metrics using actual costs\n",
        "    results_df[\"Efficiency Score\"] = results_df[\"Quality Score\"] / results_df[\"Avg Cost ($)\"]\n",
        "    results_df[\"Time-Efficiency\"] = results_df[\"Quality Score\"] / (results_df[\"Avg Cost ($)\"] * results_df[\"Avg Time (s)\"])\n",
        "    \n",
        "    print(\"RAGAS evaluation completed for all retrievers.\")\n",
        "    \n",
        "    return results_df, ragas_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_retrievers_with_langsmith_direct(retrievers, testset_dataset, llm):\n",
        "\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    \n",
        "\n",
        "    # DÉFINITION DES COÛTS DE GÉNÉRATION (GPT-4.1-nano)\n",
        "    GENERATION_INPUT_COST = 0.0000001  # $0.10 par million de tokens\n",
        "    GENERATION_OUTPUT_COST = 0.0000004  # $0.40 par million de tokens\n",
        "    \n",
        "    # Création du client LangSmith\n",
        "    client = Client(api_url=\"https://api.smith.langchain.com\")\n",
        "    \n",
        "    # Création d'un projet unique\n",
        "    project_name = f\"john-wick-retrieval-{uuid.uuid4().hex[:8]}\"\n",
        "    print(f\"LangSmith project name: {project_name}\")\n",
        "    \n",
        "    # Création du projet\n",
        "    client.create_project(project_name=project_name)\n",
        "    print(f\"Project '{project_name}' created successfully in LangSmith\")\n",
        "    \n",
        "    # Résultats\n",
        "    results = []\n",
        "    latency_details = {}  # Pour stocker les détails de latence par retriever\n",
        "    \n",
        "    # RAG prompt template\n",
        "    RAG_TEMPLATE = \"\"\"\\\n",
        "    You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "    If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "    Query:\n",
        "    {question}\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "    \"\"\"\n",
        "\n",
        "    rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
        "    \n",
        "    # Storage pour les testsets mis à jour\n",
        "    updated_testsets = {}\n",
        "    \n",
        "    # Évaluation de chaque retriever\n",
        "    for retriever_info in retrievers:\n",
        "        name = retriever_info[\"name\"]\n",
        "        retriever = retriever_info[\"retriever\"]\n",
        "        \n",
        "        print(f\"\\nEvaluating: {name}\")\n",
        "        \n",
        "        # Structure pour stocker les métriques\n",
        "        latency_details[name] = {\n",
        "            \"retrieval_times\": [],\n",
        "            \"llm_times\": [],\n",
        "            \"total_times\": [],\n",
        "            \"processing_times\": [],\n",
        "            \"prompt_tokens\": [],\n",
        "            \"completion_tokens\": [],\n",
        "            \"costs\": []\n",
        "        }\n",
        "        \n",
        "        # Deep copy du testset\n",
        "        retriever_testset = deepcopy(testset_dataset)\n",
        "        document_counts = []\n",
        "        retrieval_times = []\n",
        "        llm_times = []\n",
        "        processing_times = []\n",
        "        prompt_tokens_list = []\n",
        "        completion_tokens_list = []\n",
        "        costs_list = []\n",
        "        run_ids = []  # Pour tracer explicitement les IDs\n",
        "        \n",
        "        # Construire la chaîne RAG\n",
        "        rag_chain = (\n",
        "            {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "            | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "            | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        "        )\n",
        "        \n",
        "        # Test sur chaque question\n",
        "        for i, test_row in enumerate(tqdm(retriever_testset, desc=f\"Testing {name}\")):\n",
        "            try:\n",
        "                # Question\n",
        "                question = test_row.eval_sample.user_input\n",
        "                \n",
        "                # 1. Temps de récupération\n",
        "                retrieval_start = time.time()\n",
        "                context_result = retriever.invoke(question)\n",
        "                retrieval_time = time.time() - retrieval_start\n",
        "                retrieval_times.append(retrieval_time)\n",
        "                latency_details[name][\"retrieval_times\"].append(retrieval_time)\n",
        "                \n",
        "                # 2. Temps de traitement intermédiaire\n",
        "                processing_start = time.time()\n",
        "                context_text = \"\\n\\n\".join([doc.page_content for doc in context_result])\n",
        "                formatted_prompt = rag_prompt.format(question=question, context=context_text)\n",
        "                processing_time = time.time() - processing_start\n",
        "                processing_times.append(processing_time)\n",
        "                latency_details[name][\"processing_times\"].append(processing_time)\n",
        "                \n",
        "                # CALCUL EXPLICITE DES TOKENS DE GÉNÉRATION\n",
        "            \n",
        "                prompt_tokens = len(encoding.encode(formatted_prompt))\n",
        "                prompt_tokens_list.append(prompt_tokens)\n",
        "                latency_details[name][\"prompt_tokens\"].append(prompt_tokens)\n",
        "               \n",
        "                # 3. Temps du LLM\n",
        "                llm_start = time.time()\n",
        "                llm_response = llm.invoke(formatted_prompt)\n",
        "                llm_time = time.time() - llm_start\n",
        "                llm_times.append(llm_time)\n",
        "                latency_details[name][\"llm_times\"].append(llm_time)\n",
        "                \n",
        "                # Calcul des tokens de complétion\n",
        "             \n",
        "                completion_tokens = len(encoding.encode(llm_response.content))\n",
        "                completion_tokens_list.append(completion_tokens)\n",
        "                latency_details[name][\"completion_tokens\"].append(completion_tokens)\n",
        "                \n",
        "                \n",
        "                # CALCUL EXPLICITE DU COÛT DE GÉNÉRATION\n",
        "                cost = (prompt_tokens * GENERATION_INPUT_COST / 1000) + (completion_tokens * GENERATION_OUTPUT_COST / 1000)\n",
        "                costs_list.append(cost)\n",
        "                latency_details[name][\"costs\"].append(cost)\n",
        "                \n",
        "                # 4. Temps total\n",
        "                total_time = retrieval_time + processing_time + llm_time\n",
        "                latency_details[name][\"total_times\"].append(total_time)\n",
        "                \n",
        "                # Nombre de documents\n",
        "                doc_count = len(context_result)\n",
        "                document_counts.append(doc_count)\n",
        "                \n",
        "                # Mise à jour du testset\n",
        "                test_row.eval_sample.response = llm_response.content\n",
        "                test_row.eval_sample.retrieved_contexts = [\n",
        "                    doc.page_content for doc in context_result\n",
        "                ]\n",
        "                \n",
        "                # CRÉATION MANUELLE DU RUN DANS LANGSMITH\n",
        "                run_id = str(uuid.uuid4())\n",
        "                run_ids.append(run_id)\n",
        "                \n",
        "                try:\n",
        "                    # Créer run avec API directe\n",
        "                    client.create_run(\n",
        "                        name=f\"{name}-question-{i}\",\n",
        "                        inputs={\"question\": question},\n",
        "                        outputs={\n",
        "                            \"response\": llm_response.content,\n",
        "                            \"documents\": [doc.page_content for doc in context_result]\n",
        "                        },\n",
        "                        run_type=\"chain\",\n",
        "                        tags=[name, \"retriever_evaluation\"],\n",
        "                        project_name=project_name,\n",
        "                        id=run_id,\n",
        "                        start_time=retrieval_start,\n",
        "                        end_time=llm_start + llm_time,\n",
        "                        metadata={\n",
        "                            \"retriever\": name,\n",
        "                            \"question_id\": i,\n",
        "                            \"ls_model_name\": \"gpt-4.1-nano\",  # Modèle de génération explicite\n",
        "                            \"ls_provider\": \"openai\"\n",
        "                        },\n",
        "                    )\n",
        "                    \n",
        "                    # Mettre à jour le run avec des métriques détaillées\n",
        "                    client.update_run(\n",
        "                        run_id=run_id,\n",
        "                        metrics={\n",
        "                            \"total_time\": total_time,\n",
        "                            \"retrieval_time\": retrieval_time,\n",
        "                            \"llm_time\": llm_time,\n",
        "                            \"processing_time\": processing_time,\n",
        "                            \"document_count\": doc_count,\n",
        "                            \"prompt_tokens\": prompt_tokens,\n",
        "                            \"completion_tokens\": completion_tokens,\n",
        "                            \"total_tokens\": prompt_tokens + completion_tokens,\n",
        "                            \"cost\": cost\n",
        "                        }\n",
        "                    )\n",
        "                    print(f\"Run {run_id} created successfully in LangSmith\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to create run in LangSmith: {e}\")\n",
        "                \n",
        "                # Petite pause\n",
        "                time.sleep(0.5)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error on question {i}: {e}\")\n",
        "        \n",
        "        # Stockage du testset mis à jour\n",
        "        updated_testsets[name] = retriever_testset\n",
        "        \n",
        "        # Attente pour traitement LangSmith\n",
        "        print(f\"Waiting for LangSmith to process runs for {name}...\")\n",
        "        time.sleep(10)\n",
        "        \n",
        "        # Calcul des moyennes de nos métriques manuelles\n",
        "        avg_docs = np.mean(document_counts) if document_counts else 0\n",
        "        avg_retrieval_time = np.mean(retrieval_times) if retrieval_times else 0\n",
        "        avg_llm_time = np.mean(llm_times) if llm_times else 0\n",
        "        avg_processing_time = np.mean(processing_times) if processing_times else 0\n",
        "        avg_total_time = avg_retrieval_time + avg_llm_time + avg_processing_time\n",
        "        \n",
        "        avg_prompt_tokens = np.mean(prompt_tokens_list) if prompt_tokens_list else 0\n",
        "        avg_completion_tokens = np.mean(completion_tokens_list) if completion_tokens_list else 0\n",
        "        avg_cost = np.mean(costs_list) if costs_list else 0\n",
        "        \n",
        "        # Vérification directe des runs créés par ID\n",
        "        print(f\"Verifying runs directly by ID...\")\n",
        "        verified_runs = []\n",
        "        for run_id in run_ids:\n",
        "            try:\n",
        "                run = client.read_run(run_id)\n",
        "                verified_runs.append(run)\n",
        "                print(f\"Run {run_id} verified in LangSmith\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not verify run {run_id}: {e}\")\n",
        "        \n",
        "        # Récupération des métriques uniquement à partir des runs vérifiés\n",
        "        langsmith_times = []\n",
        "        langsmith_costs = []\n",
        "        \n",
        "        for run in verified_runs:\n",
        "            if hasattr(run, \"metrics\") and run.metrics:\n",
        "                metrics = run.metrics\n",
        "                if \"total_time\" in metrics:\n",
        "                    langsmith_times.append(metrics[\"total_time\"])\n",
        "                if \"cost\" in metrics:\n",
        "                    langsmith_costs.append(metrics[\"cost\"])\n",
        "        \n",
        "        # Utilisation des métriques manuelles comme fallback\n",
        "        if not langsmith_times:\n",
        "            print(\"No LangSmith timing data found, using manually tracked times\")\n",
        "            avg_langsmith_time = avg_total_time\n",
        "        else:\n",
        "            avg_langsmith_time = np.mean(langsmith_times)\n",
        "            print(f\"Using LangSmith timing data: {avg_langsmith_time:.2f}s\")\n",
        "        \n",
        "        if not langsmith_costs:\n",
        "            print(\"No LangSmith cost data found, using manually calculated costs\")\n",
        "            avg_langsmith_cost = avg_cost\n",
        "        else:\n",
        "            avg_langsmith_cost = np.mean(langsmith_costs)\n",
        "            print(f\"Using LangSmith cost data: ${avg_langsmith_cost:.6f}/query\")\n",
        "        \n",
        "        # Nombre de questions\n",
        "        num_questions = len(testset_dataset)\n",
        "        \n",
        "        # Calcul des scores d'efficacité\n",
        "        quality_score = 0.5  # À remplacer par le score RAGAS quand disponible\n",
        "        efficiency_score = (quality_score / avg_cost) * 1000 if avg_cost > 0 else 0\n",
        "        time_efficiency = quality_score / avg_total_time if avg_total_time > 0 else 0\n",
        "        \n",
        "        # Stockage des résultats avec les métriques simplifiées\n",
        "        results.append({\n",
        "            \"Retriever\": name,\n",
        "            \"Avg Time (s)\": avg_langsmith_time,\n",
        "            \"Retrieval Time (s)\": avg_retrieval_time,\n",
        "            \"LLM Time (s)\": avg_llm_time,\n",
        "            \"Processing Time (s)\": avg_processing_time,\n",
        "            \"Avg Docs\": avg_docs,\n",
        "            \"Avg Prompt Tokens\": avg_prompt_tokens,\n",
        "            \"Avg Completion Tokens\": avg_completion_tokens,\n",
        "            \"Avg Cost ($)\": avg_cost,  # Coût de génération seulement\n",
        "            \"Quality Score\": quality_score,\n",
        "            \"Efficiency Score\": efficiency_score,\n",
        "            \"Time-Efficiency\": time_efficiency\n",
        "        })\n",
        "        \n",
        "        print(f\"✓ {name}: Total {avg_langsmith_time:.2f}s (Retrieval: {avg_retrieval_time:.2f}s, LLM: {avg_llm_time:.2f}s)\")\n",
        "        print(f\"  Docs: {avg_docs:.1f}, Generation Cost: ${avg_cost:.6f}/query\")\n",
        "    \n",
        "    # Afficher le lien vers le dashboard LangSmith\n",
        "    print(f\"\\nView detailed results in LangSmith: https://smith.langchain.com/projects/{project_name}\")\n",
        "    \n",
        "    # Retourner les résultats et testsets mis à jour\n",
        "    return pd.DataFrame(results), updated_testsets, project_name, latency_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_visual_report_with_latency(results_df, latency_details=None):\n",
        "    \"\"\"\n",
        "    Generate visualizations and report including latency breakdowns\n",
        "    \"\"\"\n",
        "    # Make sure our plotting directory exists\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    \n",
        "    os.makedirs(\"evaluation_plots\", exist_ok=True)\n",
        "    \n",
        "    # Check if we have RAGAS metrics columns\n",
        "    has_ragas_metrics = \"LLM Context Recall\" in results_df.columns\n",
        "    \n",
        "    # Create standard visualizations\n",
        "    # Quality comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    quality_plot = sns.barplot(x=\"Retriever\", y=\"Quality Score\", data=results_df)\n",
        "    plt.title(\"Retriever Quality Comparison\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    for i, bar in enumerate(quality_plot.patches):\n",
        "        quality_plot.text(\n",
        "            bar.get_x() + bar.get_width()/2.,\n",
        "            bar.get_height() + 0.01,\n",
        "            f'{bar.get_height():.2f}',\n",
        "            ha='center'\n",
        "        )\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"evaluation_plots/retriever_quality.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Latency breakdown visualization\n",
        "    if \"Retrieval Time (s)\" in results_df.columns and \"LLM Time (s)\" in results_df.columns:\n",
        "        # Create a melted dataframe for the stacked bar chart\n",
        "        latency_data = pd.melt(\n",
        "            results_df, \n",
        "            id_vars=[\"Retriever\"], \n",
        "            value_vars=[\"Retrieval Time (s)\", \"LLM Time (s)\", \"Processing Time (s)\"],\n",
        "            var_name=\"Component\", \n",
        "            value_name=\"Time (s)\"\n",
        "        )\n",
        "        \n",
        "        # Create stacked bar chart for latency breakdown\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        latency_plot = sns.barplot(\n",
        "            x=\"Retriever\", \n",
        "            y=\"Time (s)\", \n",
        "            hue=\"Component\", \n",
        "            data=latency_data\n",
        "        )\n",
        "        plt.title(\"Latency Breakdown by Retriever\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.legend(title=\"Component\")\n",
        "        \n",
        "        # Add total time labels\n",
        "        for i, retriever in enumerate(results_df[\"Retriever\"]):\n",
        "            total_time = results_df.loc[results_df[\"Retriever\"] == retriever, \"Avg Time (s)\"].values[0]\n",
        "            plt.text(\n",
        "                i, \n",
        "                total_time + 0.1, \n",
        "                f'{total_time:.2f}s', \n",
        "                ha='center'\n",
        "            )\n",
        "            \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"evaluation_plots/latency_breakdown.png\")\n",
        "        plt.close()\n",
        "    \n",
        "    # If we have RAGAS metrics, create a detailed metrics comparison\n",
        "    if has_ragas_metrics:\n",
        "        # Get RAGAS metric columns\n",
        "        ragas_metrics = [\n",
        "            \"LLM Context Recall\", \n",
        "            \"Faithfulness\", \n",
        "            \"Factual Correctness\", \n",
        "            \"Response Relevancy\", \n",
        "            \"Context Entity Recall\"\n",
        "        ]\n",
        "        \n",
        "        # Create a melted dataframe for easier plotting\n",
        "        plot_data = pd.melt(\n",
        "            results_df, \n",
        "            id_vars=[\"Retriever\"], \n",
        "            value_vars=ragas_metrics,\n",
        "            var_name=\"Metric\", \n",
        "            value_name=\"Score\"\n",
        "        )\n",
        "        \n",
        "        # Create RAGAS metrics comparison chart\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        ragas_plot = sns.barplot(x=\"Metric\", y=\"Score\", hue=\"Retriever\", data=plot_data)\n",
        "        plt.title(\"RAGAS Metrics Comparison by Retriever\", fontsize=15)\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"evaluation_plots/ragas_metrics_comparison.png\")\n",
        "        plt.close()\n",
        "    \n",
        "    # Cost comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    cost_plot = sns.barplot(x=\"Retriever\", y=\"Avg Cost ($)\", data=results_df)\n",
        "    plt.title(\"Retriever Cost Comparison\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    for i, bar in enumerate(cost_plot.patches):\n",
        "        cost_plot.text(\n",
        "            bar.get_x() + bar.get_width()/2.,\n",
        "            bar.get_height() + 0.0001,\n",
        "            f'${bar.get_height():.4f}',\n",
        "            ha='center'\n",
        "        )\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"evaluation_plots/retriever_cost.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Efficiency comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    eff_plot = sns.barplot(x=\"Retriever\", y=\"Efficiency Score\", data=results_df)\n",
        "    plt.title(\"Retriever Efficiency (Quality/Cost)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    for i, bar in enumerate(eff_plot.patches):\n",
        "        eff_plot.text(\n",
        "            bar.get_x() + bar.get_width()/2.,\n",
        "            bar.get_height() + 5,\n",
        "            f'{bar.get_height():.1f}',\n",
        "            ha='center'\n",
        "        )\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"evaluation_plots/retriever_efficiency.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Enhanced visualization: Cost vs. Quality with Latency\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    scatter = plt.scatter(\n",
        "        results_df[\"Avg Cost ($)\"], \n",
        "        results_df[\"Quality Score\"],\n",
        "        s=results_df[\"Avg Time (s)\"] * 50,  # Size based on time\n",
        "        c=range(len(results_df)),  # Color based on index\n",
        "        cmap='viridis',\n",
        "        alpha=0.7\n",
        "    )\n",
        "    \n",
        "    # Add labels for each point\n",
        "    for i, row in results_df.iterrows():\n",
        "        plt.annotate(\n",
        "            row[\"Retriever\"],\n",
        "            (row[\"Avg Cost ($)\"] + 0.00005, row[\"Quality Score\"] + 0.01),\n",
        "            fontsize=10,\n",
        "            ha='center'\n",
        "        )\n",
        "    \n",
        "    # Add efficiency contour lines\n",
        "    cost_range = np.linspace(\n",
        "        results_df[\"Avg Cost ($)\"].min() * 0.8 if results_df[\"Avg Cost ($)\"].min() > 0 else 0.00001,\n",
        "        results_df[\"Avg Cost ($)\"].max() * 1.2,\n",
        "        100\n",
        "    )\n",
        "    \n",
        "    # Plot efficiency contour lines\n",
        "    efficiency_levels = [50, 100, 200, 500, 1000]\n",
        "    for level in efficiency_levels:\n",
        "        plt.plot(cost_range, level * cost_range, '--', color='gray', alpha=0.5)\n",
        "        # Label the line\n",
        "        mid_point = len(cost_range) // 2\n",
        "        plt.text(\n",
        "            cost_range[mid_point], \n",
        "            level * cost_range[mid_point], \n",
        "            f'Efficiency = {level}', \n",
        "            color='gray', \n",
        "            fontsize=8,\n",
        "            rotation=np.degrees(np.arctan(level)) if level > 0 else 0\n",
        "        )\n",
        "    \n",
        "    plt.xlabel('Cost per Query ($)', fontsize=12)\n",
        "    plt.ylabel('Quality Score', fontsize=12)\n",
        "    plt.title('Retriever Comparison: Quality vs Cost (circle size = latency)', fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.colorbar(scatter, label='Retriever Index')\n",
        "    \n",
        "    # Add a legend for the circle sizes\n",
        "    latency_sizes = [1, 3, 5, 10]\n",
        "    for size in latency_sizes:\n",
        "        plt.scatter([], [], s=size * 50, color='gray', alpha=0.5, \n",
        "                   label=f'{size}s latency')\n",
        "    plt.legend(title=\"Reference\", loc=\"upper right\")\n",
        "    \n",
        "    # Save enhanced visualization\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"evaluation_plots/enhanced_quality_cost_latency.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Find best retrievers\n",
        "    best_quality = results_df.loc[results_df[\"Quality Score\"].idxmax()][\"Retriever\"]\n",
        "    best_efficiency = results_df.loc[results_df[\"Efficiency Score\"].idxmax()][\"Retriever\"]\n",
        "    if \"Time-Efficiency\" in results_df.columns:\n",
        "        best_time_efficiency = results_df.loc[results_df[\"Time-Efficiency\"].idxmax()][\"Retriever\"]\n",
        "    else:\n",
        "        best_time_efficiency = \"Not calculated\"\n",
        "    lowest_cost = results_df.loc[results_df[\"Avg Cost ($)\"].idxmin()][\"Retriever\"]\n",
        "    fastest = results_df.loc[results_df[\"Avg Time (s)\"].idxmin()][\"Retriever\"]\n",
        "    \n",
        "    # Generate report with detailed latency breakdown\n",
        "    report = f\"\"\"\n",
        "    # Retriever Evaluation Report\n",
        "\n",
        "    ## Results Summary\n",
        "\n",
        "    | Retriever | Total Time (s) | Retrieval (s) | LLM (s) | Docs | Quality | Cost ($) | Efficiency |\n",
        "    |-----------|---------------|--------------|---------|------|---------|----------|------------|\n",
        "    \"\"\"\n",
        "    \n",
        "    # Add each row with latency breakdown\n",
        "    for _, row in results_df.iterrows():\n",
        "        retrieval_time = row.get(\"Retrieval Time (s)\", \"-\")\n",
        "        llm_time = row.get(\"LLM Time (s)\", \"-\")\n",
        "        \n",
        "        report += f\"| {row['Retriever']} | {row['Avg Time (s)']:.2f} | {retrieval_time:.2f} | {llm_time:.2f} | {row['Avg Docs']:.1f} | {row['Quality Score']:.2f} | ${row['Avg Cost ($)']:.5f} | {row['Efficiency Score']:.1f} |\\n\"\n",
        "    \n",
        "    # Add RAGAS metrics detail if available\n",
        "    if has_ragas_metrics:\n",
        "        report += f\"\"\"\n",
        "        ## RAGAS Metrics Details\n",
        "\n",
        "        | Retriever | LLM Context Recall | Faithfulness | Factual Correctness | Response Relevancy | Context Entity Recall |\n",
        "        |-----------|-------------------|--------------|---------------------|-------------------|----------------------|\n",
        "        \"\"\"\n",
        "        \n",
        "        for _, row in results_df.iterrows():\n",
        "            report += f\"| {row['Retriever']} | {row['LLM Context Recall']:.2f} | {row['Faithfulness']:.2f} | {row['Factual Correctness']:.2f} | {row['Response Relevancy']:.2f} | {row['Context Entity Recall']:.2f} |\\n\"\n",
        "    \n",
        "    # Add latency analysis section\n",
        "    report += f\"\"\"\n",
        "    ## Latency Analysis\n",
        "    \n",
        "    | Retriever | Total Time (s) | Retrieval % | LLM % | Processing % |\n",
        "    |-----------|---------------|------------|-------|--------------|\n",
        "    \"\"\"\n",
        "    \n",
        "    # Add latency percentage breakdown\n",
        "    for _, row in results_df.iterrows():\n",
        "        if \"Retrieval Time (s)\" in row and \"LLM Time (s)\" in row and \"Processing Time (s)\" in row:\n",
        "            total = row[\"Avg Time (s)\"]\n",
        "            retrieval_pct = (row[\"Retrieval Time (s)\"] / total) * 100 if total > 0 else 0\n",
        "            llm_pct = (row[\"LLM Time (s)\"] / total) * 100 if total > 0 else 0\n",
        "            processing_pct = (row[\"Processing Time (s)\"] / total) * 100 if total > 0 else 0\n",
        "            \n",
        "            report += f\"| {row['Retriever']} | {total:.2f} | {retrieval_pct:.1f}% | {llm_pct:.1f}% | {processing_pct:.1f}% |\\n\"\n",
        "    \n",
        "    # Add recommendations\n",
        "    report += f\"\"\"\n",
        "    ## Best Retrievers by Category\n",
        "\n",
        "    | Category | Best Retriever |\n",
        "    |----------|---------------|\n",
        "    | Overall Quality | {best_quality} |\n",
        "    | Cost Efficiency | {best_efficiency} |\n",
        "    | Time Efficiency | {best_time_efficiency} |\n",
        "    | Lowest Cost | {lowest_cost} |\n",
        "    | Fastest Response | {fastest} |\n",
        "\n",
        "    ## Analysis\n",
        "\n",
        "    Based on our evaluation of retrievers using the John Wick movie reviews dataset:\n",
        "\n",
        "    1. **{best_quality}** achieved the highest quality results with a score of {results_df.loc[results_df[\"Retriever\"] == best_quality, \"Quality Score\"].values[0]:.2f}. This retriever is ideal when result accuracy is the top priority.\n",
        "\n",
        "    2. **{best_efficiency}** offered the best balance of quality and cost, achieving an efficiency score of {results_df.loc[results_df[\"Retriever\"] == best_efficiency, \"Efficiency Score\"].values[0]:.1f}. This retriever is recommended for production systems where both performance and cost must be optimized.\n",
        "\n",
        "    3. **{fastest}** had the lowest overall latency at {results_df.loc[results_df[\"Retriever\"] == fastest, \"Avg Time (s)\"].values[0]:.2f}s, making it suitable for applications where response time is critical.\n",
        "\n",
        "    4. **{lowest_cost}** had the lowest cost per query at ${results_df.loc[results_df[\"Retriever\"] == lowest_cost, \"Avg Cost ($)\"].values[0]:.5f}, making it suitable for high-volume applications with tight budget constraints.\n",
        "\n",
        "    ## Tradeoffs and Recommendations\n",
        "\n",
        "    For this John Wick dataset, we recommend:\n",
        "    - **For production use**: {best_efficiency}\n",
        "    - **For development/testing**: {lowest_cost}\n",
        "    - **For real-time applications**: {fastest}\n",
        "    - **For high-stakes applications**: {best_quality}\n",
        "    \"\"\"\n",
        "    \n",
        "    # Save report\n",
        "    with open(\"retriever_evaluation_report.md\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    \n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = getpass.getpass(\"Entrez votre clé API LangSmith: \")\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = api_key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith project name: john-wick-retrieval-78860798\n",
            "Project 'john-wick-retrieval-78860798' created successfully in LangSmith\n",
            "\n",
            "Evaluating: Naive Retriever\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1eb281c2fba4d39885b51dad55a365e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing Naive Retriever:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run db449b3d-cb1d-4830-8db9-00c6b7737efe created successfully in LangSmith\n",
            "Run 4cac183a-a48f-40fb-865a-56e1121e9d29 created successfully in LangSmith\n",
            "Run e8a08bf2-354f-48c2-9233-650964ef885c created successfully in LangSmith\n",
            "Run 579b8f63-ced6-4ca4-bbe6-50919c4c5ad4 created successfully in LangSmith\n",
            "Run caef9e7c-3e66-4a86-8cde-276fd0d9e17e created successfully in LangSmith\n",
            "Run d8cb4dea-4993-412a-be20-8e90c4e90e86 created successfully in LangSmith\n",
            "Run c818a596-d879-47a6-93f1-5d303c1b0794 created successfully in LangSmith\n",
            "Run 27486d8d-6904-4de9-98aa-450ae0b6b02b created successfully in LangSmith\n",
            "Run 820b1b1b-bf6a-47df-8028-12f4aacc19bf created successfully in LangSmith\n",
            "Run ab3f0811-46dd-45f4-b79c-a104676ff4ba created successfully in LangSmith\n",
            "Run 904ad880-69a3-4565-bb55-d24bcb7b680b created successfully in LangSmith\n",
            "Run 876c9e51-360b-42a7-bf5e-a89d2332c587 created successfully in LangSmith\n",
            "Waiting for LangSmith to process runs for Naive Retriever...\n",
            "Verifying runs directly by ID...\n",
            "Run db449b3d-cb1d-4830-8db9-00c6b7737efe verified in LangSmith\n",
            "Run 4cac183a-a48f-40fb-865a-56e1121e9d29 verified in LangSmith\n",
            "Run e8a08bf2-354f-48c2-9233-650964ef885c verified in LangSmith\n",
            "Run 579b8f63-ced6-4ca4-bbe6-50919c4c5ad4 verified in LangSmith\n",
            "Run caef9e7c-3e66-4a86-8cde-276fd0d9e17e verified in LangSmith\n",
            "Run d8cb4dea-4993-412a-be20-8e90c4e90e86 verified in LangSmith\n",
            "Run c818a596-d879-47a6-93f1-5d303c1b0794 verified in LangSmith\n",
            "Run 27486d8d-6904-4de9-98aa-450ae0b6b02b verified in LangSmith\n",
            "Run 820b1b1b-bf6a-47df-8028-12f4aacc19bf verified in LangSmith\n",
            "Run ab3f0811-46dd-45f4-b79c-a104676ff4ba verified in LangSmith\n",
            "Run 904ad880-69a3-4565-bb55-d24bcb7b680b verified in LangSmith\n",
            "Run 876c9e51-360b-42a7-bf5e-a89d2332c587 verified in LangSmith\n",
            "No LangSmith timing data found, using manually tracked times\n",
            "No LangSmith cost data found, using manually calculated costs\n",
            "✓ Naive Retriever: Total 12.01s (Retrieval: 0.54s, LLM: 11.47s)\n",
            "  Docs: 10.0, Generation Cost: $0.000000/query\n",
            "\n",
            "Evaluating: BM25 Retriever\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d410fcf42ec74865a052ee5ea7be7993",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing BM25 Retriever:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 0c2d9179-6a07-41e6-9f05-39206bec2ff9 created successfully in LangSmith\n",
            "Run a061ba16-2aff-43f2-91d8-6c083e29748b created successfully in LangSmith\n",
            "Run a7a57139-7640-4709-bc70-e04e0b02897e created successfully in LangSmith\n",
            "Run e409da40-ef45-499d-a27b-a25c2faa7bd7 created successfully in LangSmith\n",
            "Run b5774cd2-5d19-40ff-aac4-d5f6deac0fc9 created successfully in LangSmith\n",
            "Run b7145354-4d49-4d89-9401-d0377b12986f created successfully in LangSmith\n",
            "Run a3b6e33d-50a8-4599-a2d1-287f023b2b5d created successfully in LangSmith\n",
            "Run c9fd801b-bc33-4fb5-84d9-0c9179a4e522 created successfully in LangSmith\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exécuter l'évaluation avec la capture de latence détaillée\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results_df, updated_testsets, project_name, latency_details = \u001b[43mevaluate_retrievers_with_langsmith_direct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretrievers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_llm\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mevaluate_retrievers_with_langsmith_direct\u001b[39m\u001b[34m(retrievers, testset_dataset, llm)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# 3. Temps du LLM\u001b[39;00m\n\u001b[32m    107\u001b[39m llm_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m llm_response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m llm_time = time.time() - llm_start\n\u001b[32m    110\u001b[39m llm_times.append(llm_time)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:959\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    957\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Archives/01_Projets/02_AIM/AIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Exécuter l'évaluation avec la capture de latence détaillée\n",
        "results_df, updated_testsets, project_name, latency_details = evaluate_retrievers_with_langsmith_direct(\n",
        "    retrievers, testset_dataset, eval_llm\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Générer le rapport avec les détails de latence\n",
        "report = generate_visual_report_with_latency(results_df, latency_details)\n",
        "print(f\"Rapport créé: retriever_evaluation_report.md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher le graphique amélioré avec les données de latence\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(\n",
        "    results_df[\"Avg Cost ($)\"], \n",
        "    results_df[\"Quality Score\"],\n",
        "    s=results_df[\"Avg Time (s)\"] * 50,  # Taille basée sur le temps\n",
        "    c=range(len(results_df)),  # Couleur basée sur l'index\n",
        "    cmap='viridis',\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "# Ajouter les étiquettes pour chaque point\n",
        "for i, row in results_df.iterrows():\n",
        "    plt.annotate(\n",
        "        row[\"Retriever\"],\n",
        "        (row[\"Avg Cost ($)\"] + 0.00005, row[\"Quality Score\"] + 0.01),\n",
        "        fontsize=10,\n",
        "        ha='center'\n",
        "    )\n",
        "\n",
        "plt.xlabel('Coût par requête ($)', fontsize=12)\n",
        "plt.ylabel('Score de qualité', fontsize=12)\n",
        "plt.title('Comparaison des retrievers: Qualité vs Coût vs Latence', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.colorbar(scatter, label='Index du retriever')\n",
        "\n",
        "# Ajouter une légende pour les tailles de cercle\n",
        "latency_sizes = [1, 3, 5, 10]\n",
        "for size in latency_sizes:\n",
        "    plt.scatter([], [], s=size * 50, color='gray', alpha=0.5, \n",
        "               label=f'{size}s latence')\n",
        "plt.legend(title=\"Référence\", loc=\"upper right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"evaluation_plots/interactive_latency_viz.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#US Personnal\n",
        "#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\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
