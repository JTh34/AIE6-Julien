1. Title: Extending Llama-3's Context Ten-Fold Overnight
2. Authors: Not explicitly listed
3. Publication Date: April 30, 2024
4. Key Findings:
5.   - Method to increase Llama-3-8B-Instruct's context from 8,000 to 80,000 tokens.
6.   - Enhancement allows effective processing of longer texts while retaining short context capabilities.
7. Methodology:
8.   - Application of Quantized Low-Rank Adaptation (QLoRA) for model fine-tuning.
9.   - Use of small dataset of synthetic long-context examples generated by GPT-4.
10.   - Efficient fine-tuning completed in 8 hours using powerful GPU (8xA800, 80G).
