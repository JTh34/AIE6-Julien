{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_book_chunks(file_path: str) -> List[dict]:\n",
    "    \"\"\"Load chunks from the JSON file.\"\"\"\n",
    "    print(f\"ğŸ“š Loading chunks from {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… {len(chunks)} chunks loaded\")\n",
    "    return chunks\n",
    "\n",
    "def convert_to_documents(chunks: List[dict]) -> List[Document]:\n",
    "    \"\"\"Convert JSON chunks to LangChain Documents.\"\"\"\n",
    "    print(\"ğŸ”„ Converting to LangChain Documents...\")\n",
    "    \n",
    "    documents = []\n",
    "    for chunk in tqdm(chunks, desc=\"Conversion\"):\n",
    "        # Create the Document with content and metadata\n",
    "        doc = Document(\n",
    "            page_content=chunk[\"page_content\"],\n",
    "            metadata=chunk[\"metadata\"]\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    print(f\"âœ… {len(documents)} documents created\")\n",
    "    return documents\n",
    "\n",
    "def setup_qdrant_with_books(\n",
    "    qdrant_url: str = \"http://localhost:6333\",\n",
    "    collection_name: str = \"puppy_books\",\n",
    "    embedding_model: str = \"mxbai-embed-large\",\n",
    "    ollama_base_url: str = \"http://localhost:11434\"\n",
    "):\n",
    "    \"\"\"Set up QDrant and embeddings.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ Setting up QDrant and embeddings...\")\n",
    "    \n",
    "    # QDrant Client\n",
    "    client = QdrantClient(url=qdrant_url)\n",
    "    \n",
    "    # Embeddings via Ollama\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        base_url=ollama_base_url,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    \n",
    "    # Test embeddings\n",
    "    print(\"ğŸ§ª Testing embeddings...\")\n",
    "    test_embedding = embeddings.embed_query(\"test embedding\")\n",
    "    embedding_dim = len(test_embedding)\n",
    "    print(f\"âœ… Embeddings OK (dimension: {embedding_dim})\")\n",
    "    \n",
    "    # Check if collection exists, if not create it\n",
    "    try:\n",
    "        client.get_collection(collection_name)\n",
    "        print(f\"ğŸ“ Collection '{collection_name}' already exists\")\n",
    "    except Exception:\n",
    "        print(f\"ğŸ“ Creating collection '{collection_name}'...\")\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE)\n",
    "        )\n",
    "        print(f\"âœ… Collection '{collection_name}' created\")\n",
    "    \n",
    "    # VectorStore\n",
    "    vectorstore = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    return vectorstore, client, embedding_dim\n",
    "\n",
    "def populate_qdrant(\n",
    "    file_path: str,\n",
    "    qdrant_url: str = \"http://localhost:6333\",\n",
    "    collection_name: str = \"puppy_books\",\n",
    "    embedding_model: str = \"mxbai-embed-large\",\n",
    "    ollama_base_url: str = \"http://localhost:11434\",\n",
    "    batch_size: int = 50  # Process in batches to avoid timeouts\n",
    "):\n",
    "    \"\"\"Populate QDrant with book chunks.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ• === POPULATING QDRANT WITH PUPPY BOOKS ===\\n\")\n",
    "    \n",
    "    # 1. Load data\n",
    "    chunks = load_book_chunks(file_path)\n",
    "    \n",
    "    # 2. Convert to Documents\n",
    "    documents = convert_to_documents(chunks)\n",
    "    \n",
    "    # 3. Initial client for collection management\n",
    "    client = QdrantClient(url=qdrant_url)\n",
    "    \n",
    "    # 4. Check if the collection already exists and delete if needed\n",
    "    try:\n",
    "        collection_info = client.get_collection(collection_name)\n",
    "        print(f\"âš ï¸  Collection '{collection_name}' already exists with {collection_info.points_count} points\")\n",
    "        \n",
    "        response = input(\"Do you want to delete and recreate it? (y/N): \")\n",
    "        if response.lower() == 'y':\n",
    "            client.delete_collection(collection_name)\n",
    "            print(\"ğŸ—‘ï¸  Collection deleted\")\n",
    "        else:\n",
    "            print(\"â• Adding new documents to the existing collection\")\n",
    "    except Exception:\n",
    "        print(f\"ğŸ“ Collection '{collection_name}' doesn't exist yet\")\n",
    "    \n",
    "    # 5. Setup QDrant after potential deletion\n",
    "    vectorstore, client, embedding_dim = setup_qdrant_with_books(\n",
    "        qdrant_url, collection_name, embedding_model, ollama_base_url\n",
    "    )\n",
    "    \n",
    "    # 6. Add documents in batches\n",
    "    print(f\"\\nğŸ“¥ Adding {len(documents)} documents to QDrant...\")\n",
    "    print(f\"ğŸ’¡ Processing in batches of {batch_size} documents\")\n",
    "    \n",
    "    total_added = 0\n",
    "    for i in tqdm(range(0, len(documents), batch_size), desc=\"Batch adding\"):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        \n",
    "        try:\n",
    "            vectorstore.add_documents(batch)\n",
    "            total_added += len(batch)\n",
    "            \n",
    "            # Progress display\n",
    "            if (i // batch_size + 1) % 5 == 0:  # Every 5 batches\n",
    "                print(f\"   ğŸ“Š {total_added}/{len(documents)} documents added\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error while adding batch {i//batch_size + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 7. Final check\n",
    "    try:\n",
    "        collection_info = client.get_collection(collection_name)\n",
    "        print(f\"\\nâœ… Population complete!\")\n",
    "        print(f\"ğŸ“Š Collection '{collection_name}': {collection_info.points_count} points\")\n",
    "        print(f\"ğŸ“ Vector dimension: {embedding_dim}\")\n",
    "        \n",
    "        # Search test\n",
    "        print(\"\\nğŸ” Search test...\")\n",
    "        test_results = vectorstore.similarity_search(\n",
    "            \"how to choose a puppy\", \n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Search test OK: {len(test_results)} results found\")\n",
    "        for i, doc in enumerate(test_results[:2]):\n",
    "            print(f\"   ğŸ“„ Result {i+1}: {doc.page_content[:100]}...\")\n",
    "            print(f\"      ğŸ“š Source: {doc.metadata.get('book_title', 'N/A')}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during verification: {e}\")\n",
    "        return False\n",
    "\n",
    "def search_books(\n",
    "    query: str,\n",
    "    collection_name: str = \"puppy_books\",\n",
    "    k: int = 5,\n",
    "    qdrant_url: str = \"http://localhost:6333\",\n",
    "    embedding_model: str = \"mxbai-embed-large\",\n",
    "    ollama_base_url: str = \"http://localhost:11434\"\n",
    "):\n",
    "    \"\"\"Utility function to test searches.\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    client = QdrantClient(url=qdrant_url)\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        base_url=ollama_base_url,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    vectorstore = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Search\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    print(f\"\\nğŸ” Search: '{query}'\")\n",
    "    print(f\"ğŸ“Š {len(results)} results found\\n\")\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"ğŸ“„ Result {i} (Score: {score:.3f})\")\n",
    "        print(f\"   ğŸ“š Book: {doc.metadata.get('book_title', 'N/A')}\")\n",
    "        print(f\"   ğŸ“„ Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "        print(f\"   ğŸ“ Content: {doc.page_content[:200]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FILE_PATH = \"all_books_preprocessed_chunks.json\"  # Adjust the path if needed\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    print(f\" File not found: {FILE_PATH}\")\n",
    "\n",
    "\n",
    "# Populate QDrant\n",
    "populate_qdrant(FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Search: ''\n",
      "5 results found\n",
      "\n",
      "Result 1 (Score: 0.479)\n",
      "Book: Puppies For Dummies\n",
      "Page: 30\n",
      "Content: InÂ­Chapter 6,Â­IÂ­alsoÂ­focusÂ­onÂ­describingÂ­yourÂ­puppyâ€™sÂ­dailyÂ­needsÂ­andÂ­howÂ­toÂ­ structureÂ­aÂ­scheduleÂ­aroundÂ­them.Â­KnowingÂ­howÂ­yourÂ­puppyÂ­likesÂ­toÂ­organizeÂ­ theirÂ­dayÂ­takesÂ­theÂ­guessworkÂ­outÂ­ofÂ­thisÂ­expe...\n",
      "\n",
      "Result 2 (Score: 0.462)\n",
      "Book: Don't Shoot the Dog\n",
      "Page: 113\n",
      "Content: when compliance is obtained; reinforce even halfhearted efforts at ï¬rst.) Shine a strong light on doghouse when dog barks. Turn the light off when the dog stops barking. When the decibel level meets t...\n",
      "\n",
      "Result 3 (Score: 0.460)\n",
      "Book: Don't Shoot the Dog\n",
      "Page: 127\n",
      "Content: Kids too noisy in the car. Wait for a quiet time and then say \"You all\n",
      "\n",
      "have been so quiet today that I'm going to stop at McDonald's.\" (Say this right near\n",
      "\n",
      "Surly bus driver is rude to you and makes ...\n",
      "\n",
      "Result 4 (Score: 0.458)\n",
      "Book: Don't Shoot the Dog\n",
      "Page: 131\n",
      "Content: messy person could shape the tidy one to be more casual. Barking dogs are lonely, frightened, and bored. Give exercise and attention by day so that the dog is tired and sleepy at night, or provide ano...\n",
      "\n",
      "Result 5 (Score: 0.456)\n",
      "Book: Don't Shoot the Dog\n",
      "Page: 61\n",
      "Content: The illumination this game provides for professionals is part of the fun (and everyone else gets your insights at the same time - you can't hide, but on the other hand you are bathed in amused sympath...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Type your question about puppies: \")\n",
    "search_books(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
