{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WPwFBEs1mvV"
      },
      "source": [
        "# Bonus Activity - Unsloth GRPO Training on Open R1 Math Raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4PsmQK0fiE"
      },
      "source": [
        "### 1. Insall Unsloth for Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ioBFUk9g1mvZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm==0.7.3\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm==0.7.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sUNfTmN3tY46"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "1UTAL2sPELqS",
        "outputId": "5d7f74a2-87d8-47f2-89b8-1a16b555d346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 05-06 07:57:11 __init__.py:207] Automatically detected platform cuda.\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulien-thomazo\u001b[0m (\u001b[33mjulien-thomazo-inria\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "from vllm import SamplingParams\n",
        "from google.colab import drive\n",
        "import re\n",
        "import json\n",
        "import torch\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import wandb\n",
        "from datasets import load_dataset, Dataset\n",
        "import gc\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tRIs2TxELqT"
      },
      "source": [
        "### Helper functions to extract information and formatting system prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LlEt6yTeELqT"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "Solve the following mathematical problem step by step. Your response must follow this format:\n",
        "\n",
        "<reasoning>\n",
        "Provide a clear, step-by-step solution to the problem. Include all mathematical steps and logic.\n",
        "</reasoning>\n",
        "\n",
        "<answer>\n",
        "Write your final answer here concisely.\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "# 3. Improved XML Parsing Functions with Error Handling\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extract text between <answer> and </answer> tags with robust error handling.\"\"\"\n",
        "    try:\n",
        "        if \"<answer>\" not in text or \"</answer>\" not in text:\n",
        "            return \"\"\n",
        "        answer_start = text.find(\"<answer>\") + len(\"<answer>\")\n",
        "        answer_end = text.find(\"</answer>\", answer_start)\n",
        "        if answer_end == -1:  # If closing tag not found\n",
        "            return \"\"\n",
        "        return text[answer_start:answer_end].strip()\n",
        "    except Exception:\n",
        "        # Return empty string on any error\n",
        "        return \"\"\n",
        "\n",
        "def extract_xml_reasoning(text: str) -> str:\n",
        "    \"\"\"Extract text between <reasoning> and </reasoning> tags with robust error handling.\"\"\"\n",
        "    try:\n",
        "        if \"<reasoning>\" not in text or \"</reasoning>\" not in text:\n",
        "            return \"\"\n",
        "        reasoning_start = text.find(\"<reasoning>\") + len(\"<reasoning>\")\n",
        "        reasoning_end = text.find(\"</reasoning>\", reasoning_start)\n",
        "        if reasoning_end == -1:  # If closing tag not found\n",
        "            return \"\"\n",
        "        return text[reasoning_start:reasoning_end].strip()\n",
        "    except Exception:\n",
        "        # Return empty string on any error\n",
        "        return \"\"\n",
        "\n",
        "def clean_math_text(text: str) -> str:\n",
        "    \"\"\"Clean mathematical text by normalizing spacing and preserving LaTeX.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    try:\n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        # Preserve LaTeX delimiters\n",
        "        text = re.sub(r'(\\$+)(.*?)(\\$+)', lambda m: m.group(1) + m.group(2).replace(' ', '') + m.group(3), text)\n",
        "        return text.strip()\n",
        "    except Exception:\n",
        "        # Return original text on any error\n",
        "        return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab75OA70ELqT"
      },
      "source": [
        "### Streamlined Dataset Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5ldfboX9ELqT"
      },
      "outputs": [],
      "source": [
        "def get_open_r1_math_data(split=\"train\", max_train_examples=1000, max_test_examples=50, random_seed=42):\n",
        "    \"\"\"\n",
        "    Load the OpenR1-Math-Raw dataset with improved processing.\n",
        "    \"\"\"\n",
        "    streaming_dataset = load_dataset(\"open-r1/OpenR1-Math-Raw\", split=split, streaming=True)\n",
        "\n",
        "    filtered_dataset = streaming_dataset.filter(\n",
        "        lambda x: x[\"problem_is_valid\"] == \"Yes\"  and\n",
        "                  x[\"solution_is_valid\"] == \"Yes\" and\n",
        "                  \"proof\" not in x[\"answer\"]\n",
        "    )\n",
        "\n",
        "    transformed_dataset = filtered_dataset.map(\n",
        "        lambda x: {\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": x[\"problem\"]}\n",
        "            ],\n",
        "            \"expected_answer\": x[\"answer\"], # target to achieve\n",
        "            \"reference_solution\": x[\"solution\"], # reasoning steps\n",
        "        }\n",
        "    )\n",
        "\n",
        "    shuffled_dataset = transformed_dataset.shuffle(buffer_size=10000, seed=random_seed)\n",
        "\n",
        "    train_stream = shuffled_dataset.take(max_train_examples)\n",
        "    train_dataset = Dataset.from_list(list(train_stream))\n",
        "\n",
        "    test_stream = shuffled_dataset.take(max_test_examples)\n",
        "    test_dataset = Dataset.from_list(list(test_stream))\n",
        "\n",
        "    print(f\"Dataset loaded: {len(train_dataset)} training examples, {len(test_dataset)} test examples\")\n",
        "\n",
        "    return train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmquSjeyELqU"
      },
      "source": [
        "### Reward functions\n",
        "\n",
        "We define several reward functions:\n",
        "- for checking the correctnes of the answer\n",
        "- for checking  the reasoning length, the cpresence of mathematical symbols and LaTeX expressions\n",
        "- for checking  the compliance with the expected xml format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RKLMNZWcELqU"
      },
      "outputs": [],
      "source": [
        "def correctness_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    Reward the model for generating the correct answer.\n",
        "    This function has the highest weight (2.0) to prioritize correctness.\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    extracted_answers = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Extract the expected answers from kwargs\n",
        "    expected_answers = kwargs.get(\"expected_answer\", [\"\"] * len(completions))\n",
        "    if not isinstance(expected_answers, list):\n",
        "        expected_answers = [expected_answers] * len(completions)\n",
        "\n",
        "    # Clean up answers for comparison\n",
        "    expected_answers_clean = [a.strip() if a else \"\" for a in expected_answers]\n",
        "    extracted_answers_clean = [a.strip() for a in extracted_answers]\n",
        "\n",
        "    # Assign high reward (2.0) for correct answers\n",
        "    return [2.0 if a == e else 0.0 for a, e in zip(extracted_answers_clean, expected_answers_clean)]\n",
        "\n",
        "def reasoning_quality_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    Reward the model for providing mathematical reasoning.\n",
        "    This function has a medium weight (1.5 max) to encourage good reasoning.\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    reasoning_parts = [extract_xml_reasoning(r) for r in responses]\n",
        "\n",
        "    rewards = []\n",
        "    for reasoning in reasoning_parts:\n",
        "        # Check if reasoning exists\n",
        "        if not reasoning:\n",
        "            rewards.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Check reasoning length\n",
        "        word_count = len(reasoning.split())\n",
        "        length_reward = min(word_count / 50, 0.8)  # Clip to 0.8\n",
        "\n",
        "        # Check for mathematical symbols\n",
        "        math_expressions = len(re.findall(r'[\\+\\-\\*/=><\\(\\)\\[\\]\\{\\}]', reasoning))\n",
        "        math_reward = min(math_expressions / 10, 0.4)\n",
        "\n",
        "        # Check for LaTeX expressions\n",
        "        latex_count = len(re.findall(r'\\$.*?\\$|\\$\\$.*?\\$\\$', reasoning))\n",
        "        latex_reward = min(latex_count * 0.1, 0.3)\n",
        "\n",
        "        rewards.append(length_reward + math_reward + latex_reward)\n",
        "\n",
        "    return rewards\n",
        "\n",
        "def format_compliance_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    Reward the model for following the specified format.\n",
        "    This function has a lower weight (1.0 max) as format is important but secondary to correctness.\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    rewards = []\n",
        "    for response in responses:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Check for proper reasoning tag usage\n",
        "        if \"<reasoning>\" in response and \"</reasoning>\" in response:\n",
        "            reward += 0.4\n",
        "\n",
        "        # Check for proper answer tag usage\n",
        "        if \"<answer>\" in response and \"</answer>\" in response:\n",
        "            reward += 0.3\n",
        "\n",
        "        # Check for correct ordering (reasoning before answer)\n",
        "        if response.find(\"<reasoning>\") < response.find(\"<answer>\") and \\\n",
        "           response.find(\"</reasoning>\") < response.find(\"</answer>\"):\n",
        "            reward += 0.3\n",
        "\n",
        "        rewards.append(reward)\n",
        "\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MC-tQeUzELqU"
      },
      "outputs": [],
      "source": [
        "# Model and training configuration\n",
        "def setup_and_train():\n",
        "    \"\"\"Set up and train the model using GRPO.\"\"\"\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Load dataset with train/test split\n",
        "    train_dataset, test_dataset = get_open_r1_math_data(\n",
        "    max_train_examples=1000,\n",
        "    max_test_examples=50,\n",
        "    random_seed=42\n",
        ")\n",
        "\n",
        "    # Save the test dataset for later evaluation\n",
        "    test_dataset.save_to_disk(\"/content/drive/MyDrive/test_math_dataset_improved\")\n",
        "\n",
        "    max_seq_length = 2048\n",
        "    lora_rank = 16\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        max_seq_length = max_seq_length,\n",
        "        load_in_4bit = True,\n",
        "        fast_inference = True,\n",
        "        max_lora_rank = lora_rank,\n",
        "        gpu_memory_utilization = 0.7\n",
        "    )\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "        target_modules = [\n",
        "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "        ], # Remove QKVO if out of memory\n",
        "        lora_alpha = lora_rank,\n",
        "        use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "        random_state = 3407,\n",
        "    )\n",
        "\n",
        "    # Calculate maximum prompt length\n",
        "    max_prompt_length = max(train_dataset.map(\n",
        "        lambda x: {\"tokens\": tokenizer.apply_chat_template(x[\"prompt\"], add_generation_prompt=True, tokenize=True)},\n",
        "        batched=True,\n",
        "    ).map(lambda x: {\"length\": len(x[\"tokens\"])})[\"length\"])\n",
        "\n",
        "    max_prompt_length = max_prompt_length + 10  # Extra margin\n",
        "\n",
        "    # Configure training\n",
        "    training_args = GRPOConfig(\n",
        "        learning_rate = 5e-6,\n",
        "        weight_decay = 0.1,\n",
        "        warmup_ratio = 0.1,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        optim = \"adamw_torch_fused\",\n",
        "        logging_steps = 1,\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_generations = 8,\n",
        "        max_prompt_length = max_prompt_length,\n",
        "        max_completion_length = max_seq_length - max_prompt_length,\n",
        "        # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "        max_steps = 175,\n",
        "        save_steps = 25,\n",
        "        max_grad_norm = 0.1,\n",
        "        report_to = \"wandb\",\n",
        "        output_dir = \"outputs_math_reasoning_improved\",\n",
        "    )\n",
        "\n",
        "    # Create and configure GRPO trainer\n",
        "    trainer = GRPOTrainer(\n",
        "        model = model,\n",
        "        processing_class = tokenizer,\n",
        "        reward_funcs = [\n",
        "            correctness_reward_func,\n",
        "            reasoning_quality_reward_func,\n",
        "            format_compliance_reward_func\n",
        "        ],\n",
        "        args = training_args,\n",
        "        train_dataset = train_dataset,\n",
        "    )\n",
        "\n",
        "    # Start training\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model after training\n",
        "    model.save_lora(\"/content/drive/MyDrive/math_reasoning_grpo_lora_improved\")\n",
        "\n",
        "    return model, tokenizer, test_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G5Z0AYRQsC0"
      },
      "source": [
        "### Train the model and save test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fe147625991d4a4886971cc549b75bfc",
            "f14e639c3a8c443a9edcea05da48ff5d",
            "f182c90ed4ab45f5930ac988fe881297",
            "364c44300e9541e68cef7032cb1568ff",
            "5f4d6671108f442aaf01bb9c4d298968",
            "57ccb6cabb7b4a24a18aa1281645d91b",
            "36f56e7b792b4e33951d392e15a4e974",
            "da1a21f84f72481ea183adf385882c9f",
            "ee9c533226034f4885086ec1de98c347",
            "3eb01203eb52400a9a44a248b8de2986",
            "5c0e363e3dd0408fa0283c110bdc02b5",
            "b62e1380aafb4d1c8cdbb93c34aa976e",
            "2a137b63f71241558a5e73dd42d5ae4e",
            "acb9d702cfba4a8aa3c50ebd5900f8ff",
            "f167907e8789452b85790c553e8c4b06",
            "5a37bd680acd41cb960fb22f29cc64a2",
            "2e28789cbad1495ebff65105c7d6bcc3",
            "3f4bc457c0b6441e849638b8f77df617",
            "a88a3e32cae44487aea1f4b975b12bb4",
            "74b8b8484f3247b481376f53a44e6656",
            "084dd916aa1d4dbf9b4fac4b2494c9a2",
            "d83c2e843be340979f3d2c70ab393bc5",
            "7873fecc34d844b59d6b37da86607b09",
            "db11a274da4f42188fc5d1ca92be9f64",
            "c2b6fe1e01e5475c98179ae7c5033109",
            "6c24ecccaf5f4ff684576ed2f5402540",
            "33c01979e70240aba0145d1e75f5d613",
            "a583cd03fe3b4dfdb586bd131a72b48b",
            "687fa046b30247b78d90e5c6d27cec5b",
            "5aabaae025084264a79d69b32e32d1c3",
            "e8877f7c2ac64a32a813ba0b563afba6",
            "95fcdef73f9d410a88f83ab4f921bd11",
            "396f4f6b37c3449c9ceceda4f10be579",
            "195836c7228e4d4c9dce53d3e34073e1",
            "fc5911b7d4544bc1b23902d52362884e",
            "96583d18090d4e63969e5945373ce6c2",
            "6d95879ef0ab482fa2b2569b4fc2e1c3",
            "cdb197ce064b443f9a2d5b3f8ef843f9",
            "6c19d1ca208f4a4fab0191ae9f769cea",
            "dbe5f2f0b0c94741a4781d120c1ae05b",
            "40aafcb4abeb429786df6751e02b8e8d",
            "a7b5eb8e5dcc4f34911de76a96bdb821",
            "438916788b854d1bbe90341b23c90a4d",
            "9c6d64f3305541889911030fc940a8ff",
            "e62b62cbd25f4a6dbbaa1b191f1eaa42",
            "e13a45c63af747dbbf1a8245dcce8aaa",
            "a30d2feb732f41368fb3c1bcb9f12209",
            "9dbfe80dcb794ffd9211e4228dd8a969",
            "eef30010db5e40a4a0a66c25c9b6c19f",
            "a70d1df43b434766990b77e740cff242",
            "975adedb299841b8baa75d720dfe7dbb",
            "9a5cb6a06eae498084ab564a373d243d",
            "a72c0966b212435496c52a0333207556",
            "ce2f052e461c4658a3be285ee2f5344f",
            "b5a2c6c04ec44336b9f369164e2e3be7",
            "f584597a6a0042d6b6d726bda6f6ea78",
            "cfeca3e98cd14ef1b506c8786c5ab614",
            "134aa7f09c264058a9c126d42d3a420e",
            "ffee99a053f84d9d8fe3d23ca5124940",
            "f6fab47c1c844294b4c83a09b4b363b7",
            "28720a1e1e224258b5657fef254d332c",
            "c11f8e6fe77c4f159ea43454a421dad8",
            "b1d92dfe57564379ab5816baa6571bf2",
            "a8ac2e5b435d4b24aa63c19238662f55",
            "693dd06972b7489ba2f86e3ac769b69d",
            "1d1a888b56384f62b93a86c796ac98a5",
            "657e3769012b40fe944acecef5f17c0e",
            "f87c709ed3fb4a15b837142438a95488",
            "3d8f96d0ad9e4226bc3f2bda323ca477",
            "d38499194165440c8e4268436ec2094b",
            "088c0d4fef204217917f15ef0370bf4f",
            "c6e557dc435045479fbaad24723cbd88",
            "c7594bf8c3fa4e968524dea4d4240089",
            "5c1cbe91755f44e1afdaa76fd82f7a1b",
            "4a731e1df276418b8f6b1dfbd6e88714",
            "f76f4ab1897049a0a3568083554fff15",
            "e0b53f9c5e9f48f4ae26c4f7574c7876",
            "ee3292c4cda6471d95d0e7ebec678224",
            "fdaa7b8abd714b35b3e585ada9ad8a1f",
            "1d1b76b9f5d94ae68154707e6964fa50",
            "131de72f98cf4053941a3b44757c3370",
            "09a3fade2343411f9e0c88c620b3bd52",
            "2b44d7b00d544d169804fedb36f89cc8",
            "ec27ca651846432db544247106918c38",
            "cdbfb32febe145318bdb21c604852c69",
            "c47c3932f03847d59d7cc08ecc2c408d",
            "49e7bb508f824a7f8d194c334c9c6a26",
            "82819ca594e340d783a39a2fbc49c095",
            "d3e2e56eeb0548839054ae82897333a5",
            "1cc97a2fdb87449f9d0442fa404ca7c3",
            "a0ea7778d4754150a5356c45f655df15",
            "6cb2ab966d814073ad99655b7e20fdd4",
            "6944e598a34b4f4b8e65e7f2010c1446",
            "c51c6139d3a743d094ad1d29c4ecfa56",
            "8f888d6a9ec54d578724853b697a8cf4",
            "9b7a460ca0064660a2332ff65fbc0888",
            "7d4858cac5674e228d997b0a14ef22b6",
            "56f92cebc6f2451380d2e388a2ecd3a0",
            "6a47d8701b0c440b8d83e975d886aebe",
            "f050735f99004c2a81c68362b0bb637a",
            "bd514bd402c94cd39baab163d7b71566",
            "f95fc608f5f94b828068c1c68e86b39f",
            "9f8fefb818a6472a9d3f8616e261f258",
            "77b651fab0c24b41bc7f692e8dc3db2c",
            "9e71e4fb5d5640ecb62a0aa712c73bb8",
            "32e502c83469492c917e65634b8d829a",
            "e828c58979fb46cc9765650bc450329b",
            "fa933a51d4b347b982d7e123badf02ec",
            "079cc23f394a4ab7a56ccba660a01d25",
            "a85e0530c0374e0394aa67e5bc4553e5",
            "c1e6e47654b0427abc222b02ce1be6f3",
            "6dce52eb71714213b7e509ce5148e1f0",
            "a99d243827524730806dba6e3cab496f",
            "889b7e5edd564a5895a6a79a1ef14989",
            "c4338972723548a492d3d33fe5e6e99f",
            "d52757b449644729b9d1e76da3e21e9b",
            "f81ac1d82c9e4a3fa1f36c2af116ee48",
            "32851239808a463bb47a833ddc594d5e",
            "1263f0b83ef544ada62bba3526389abc",
            "3235dfd075884b48866f0d3cfa3cf5d1",
            "330ff0d1f13a4ee09ee8095cc6ff3459",
            "554c476846b54806af8ca92fac440236",
            "d97d42c81d2b4620bc7bbe42ab322bb9",
            "23924879272d46ae8cf9eec541ca60f9",
            "4e36933ecaf44b27abed5d01133b0900",
            "b3e323a7540e4abaa3a7436ad5bea5e7",
            "6eae3149ebe14d29b9bf871c9e22f441",
            "12b951eabcc94457bc08b4de97b9d37e",
            "b29a6919fb3b40729ce39b51c62bf0b6",
            "5602cc05e78c44469b68c5044e10f023",
            "cacf570bdb494eada321c69317c64749",
            "c9a26b2e27034bf4a010ade5f0a7abcb",
            "63f682d981104effbfefa6456f0b5aff",
            "4d93368f27864356860c9bb127eaf600",
            "771856f917844e299f050fd851cad311",
            "0a9d0b155dc94ba3ad5d5b1f58a63ede",
            "0890bf9d7ad940f887c59d4441126305",
            "05a69042f2904099beb323cdcf5e24c7",
            "7cbb6245548c4e5e94284c7c0a1235c1",
            "8830e0a73bb742f587fb0aab4e9670de",
            "824169749a12469fb8ba7c736f66688f",
            "61151f449bfd4cf58e941d6decf42ae2",
            "385bdb7f718047dca8d3fc26342976e9",
            "9d0c7aab80284522bfbddc2ec8c7e9fe",
            "3aba47aa95dc4a69a96a95a03b14fc1a",
            "bf8f285b261e478b99390fafa20a6123",
            "b3f69b21d4c3402e93fc4bbccb35af52",
            "507bbbf678f2467097ce6ca1a78e849d",
            "d943c35048fe4ce789bef752d24f85b0",
            "d800627d66e14363826b63c8f74ff21a",
            "4a28e7b67a62462b8f0370a3a2902726",
            "a1e9daa0e912436581ae72af9bc426d5",
            "194c4809986c4d9a8e45209e09ca76a5",
            "815adc2556604741b59352cc6ce24596",
            "f05b5123b6814a3a9abea1b80c77c12b",
            "29c4d27ee77c4699bc07a0cf0265aafc",
            "828b21577f7f4829b8697f0890f911ca",
            "165a360d81d14492a34b2d29253b58b6",
            "eeb9ebe921b3458cabb91c3eb3b589fd",
            "766f4da859ea443faf6e5950f3a628a9",
            "aa797f75546b48258f50bc8adb8a60d3",
            "edc7103da81444e19a6cf7330cb9bedd",
            "6bfad1497dc749859ebd8a3782a00726",
            "968704706f5a4c50a508c5c8f377f849",
            "d6289f27625d47bb8dd715aea3334a8b",
            "b40d5a0b9dd9433bbe1f103a77aa8dc8",
            "2ebf3a4a0741425985f1c21abbb5a65c",
            "fc793bf44b8b43fb82ce72dec3bbfd05",
            "85ff0f08b2ba4eb3b8049abe32471541",
            "daba1de13cea4ec093d4b0ff63dedeb3",
            "22d33c20ffde40f486a0612cdf3983a6",
            "546b92cf83bc42a2b0ae248441fdde0e",
            "fad8e2a77b134a7f99d4c5c9702e6c63",
            "89adb3d801d341db8864bae60b8fa3e1",
            "ba244f71da704fd893f7389fb16e7dc3",
            "c791fbe440134f329e55ad3ac9ffd518"
          ]
        },
        "id": "JxTUK89IQpbb",
        "outputId": "b9851777-090d-4cbb-f95a-01b19c7d8733"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe147625991d4a4886971cc549b75bfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.29k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62e1380aafb4d1c8cdbb93c34aa976e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/39 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7873fecc34d844b59d6b37da86607b09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/39 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded: 1000 training examples, 50 test examples\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "195836c7228e4d4c9dce53d3e34073e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.7.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 69.2%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 320.\n",
            "Unsloth: vLLM's KV Cache can use up to 24.95 GB. Also swap space = 6 GB.\n",
            "INFO 05-06 07:58:32 config.py:549] This model supports multiple tasks: {'generate', 'classify', 'embed', 'reward', 'score'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.1.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 05-06 07:58:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":320}, use_cached_outputs=False, \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e62b62cbd25f4a6dbbaa1b191f1eaa42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f584597a6a0042d6b6d726bda6f6ea78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "657e3769012b40fe944acecef5f17c0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3292c4cda6471d95d0e7ebec678224",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 05-06 07:58:35 cuda.py:229] Using Flash Attention backend.\n",
            "INFO 05-06 07:58:35 model_runner.py:1110] Starting to load model unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 05-06 07:58:35 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 05-06 07:58:36 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3e2e56eeb0548839054ae82897333a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 05-06 07:59:07 weight_utils.py:270] Time spent downloading weights for unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit: 31.326314 seconds\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f050735f99004c2a81c68362b0bb637a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e6e47654b0427abc222b02ce1be6f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 05-06 07:59:10 model_runner.py:1115] Loading model weights took 2.2405 GB\n",
            "INFO 05-06 07:59:10 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 05-06 07:59:19 worker.py:267] Memory profiling takes 8.43 seconds\n",
            "INFO 05-06 07:59:19 worker.py:267] the current vLLM instance can use total_gpu_memory (39.56GiB) x gpu_memory_utilization (0.69) = 27.37GiB\n",
            "INFO 05-06 07:59:19 worker.py:267] model weights take 2.24GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.49GiB; the rest of the memory reserved for KV Cache is 23.55GiB.\n",
            "INFO 05-06 07:59:19 executor_base.py:111] # cuda blocks: 13781, # CPU blocks: 3510\n",
            "INFO 05-06 07:59:19 executor_base.py:116] Maximum concurrency for 2048 tokens per request: 107.66x\n",
            "INFO 05-06 07:59:22 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 43/43 [00:57<00:00,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 05-06 08:00:20 model_runner.py:1562] Graph capturing finished in 58 secs, took 0.75 GiB\n",
            "INFO 05-06 08:00:20 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 70.58 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "554c476846b54806af8ca92fac440236",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63f682d981104effbfefa6456f0b5aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d0c7aab80284522bfbddc2ec8c7e9fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.4.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f05b5123b6814a3a9abea1b80c77c12b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b40d5a0b9dd9433bbe1f103a77aa8dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 175\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250506_080038-lal19k9g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/julien-thomazo-inria/huggingface/runs/lal19k9g' target=\"_blank\">outputs_math_reasoning_improved</a></strong> to <a href='https://wandb.ai/julien-thomazo-inria/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/julien-thomazo-inria/huggingface' target=\"_blank\">https://wandb.ai/julien-thomazo-inria/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/julien-thomazo-inria/huggingface/runs/lal19k9g' target=\"_blank\">https://wandb.ai/julien-thomazo-inria/huggingface/runs/lal19k9g</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 4:09:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / correctness_reward_func</th>\n",
              "      <th>rewards / reasoning_quality_reward_func</th>\n",
              "      <th>rewards / format_compliance_reward_func</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.337500</td>\n",
              "      <td>0.898345</td>\n",
              "      <td>526.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.575000</td>\n",
              "      <td>0.384161</td>\n",
              "      <td>358.656250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.075000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.243750</td>\n",
              "      <td>0.640645</td>\n",
              "      <td>882.312500</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.431250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.787500</td>\n",
              "      <td>0.664862</td>\n",
              "      <td>585.750000</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.587500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.334375</td>\n",
              "      <td>0.607039</td>\n",
              "      <td>675.437500</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.443750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.181250</td>\n",
              "      <td>0.908065</td>\n",
              "      <td>824.281250</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.306250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.012500</td>\n",
              "      <td>0.930300</td>\n",
              "      <td>898.343750</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.356250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.742076</td>\n",
              "      <td>515.000000</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>0.262500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.122500</td>\n",
              "      <td>1.065785</td>\n",
              "      <td>771.125000</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.691250</td>\n",
              "      <td>0.431250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.303125</td>\n",
              "      <td>0.788890</td>\n",
              "      <td>733.500000</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.809375</td>\n",
              "      <td>0.493750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.528125</td>\n",
              "      <td>1.057554</td>\n",
              "      <td>788.406250</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.940625</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.803125</td>\n",
              "      <td>1.129204</td>\n",
              "      <td>955.312500</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.465625</td>\n",
              "      <td>0.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.893125</td>\n",
              "      <td>0.918944</td>\n",
              "      <td>548.625000</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.005625</td>\n",
              "      <td>0.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.415625</td>\n",
              "      <td>0.784226</td>\n",
              "      <td>593.031250</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.871875</td>\n",
              "      <td>0.418750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.318750</td>\n",
              "      <td>0.732064</td>\n",
              "      <td>678.750000</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.584375</td>\n",
              "      <td>0.950396</td>\n",
              "      <td>488.281250</td>\n",
              "      <td>0.000339</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.065625</td>\n",
              "      <td>0.456250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.606875</td>\n",
              "      <td>0.823649</td>\n",
              "      <td>263.156250</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.100625</td>\n",
              "      <td>0.443750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.612500</td>\n",
              "      <td>0.703758</td>\n",
              "      <td>837.593750</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.106250</td>\n",
              "      <td>0.506250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.790625</td>\n",
              "      <td>1.039515</td>\n",
              "      <td>354.343750</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.078125</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.031875</td>\n",
              "      <td>0.630899</td>\n",
              "      <td>449.750000</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.706875</td>\n",
              "      <td>0.325000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.903941</td>\n",
              "      <td>470.312500</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.403125</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>492.906250</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.834375</td>\n",
              "      <td>0.506250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.406250</td>\n",
              "      <td>0.818642</td>\n",
              "      <td>533.187500</td>\n",
              "      <td>0.000322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.431250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.666481</td>\n",
              "      <td>463.718750</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.237500</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.825000</td>\n",
              "      <td>0.590845</td>\n",
              "      <td>610.875000</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.606250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.053125</td>\n",
              "      <td>0.749286</td>\n",
              "      <td>716.375000</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.646875</td>\n",
              "      <td>0.343750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.646875</td>\n",
              "      <td>0.900123</td>\n",
              "      <td>604.156250</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.059375</td>\n",
              "      <td>0.587500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.106250</td>\n",
              "      <td>0.710982</td>\n",
              "      <td>669.750000</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.368750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.931250</td>\n",
              "      <td>0.529823</td>\n",
              "      <td>619.187500</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.581250</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.703125</td>\n",
              "      <td>0.751212</td>\n",
              "      <td>339.781250</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.015625</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.184375</td>\n",
              "      <td>0.633350</td>\n",
              "      <td>773.062500</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.759375</td>\n",
              "      <td>0.362500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.631250</td>\n",
              "      <td>0.697364</td>\n",
              "      <td>513.687500</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.087500</td>\n",
              "      <td>0.543750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.523125</td>\n",
              "      <td>0.896702</td>\n",
              "      <td>622.406250</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.073125</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.671875</td>\n",
              "      <td>1.110373</td>\n",
              "      <td>415.468750</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.946875</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.940625</td>\n",
              "      <td>0.363460</td>\n",
              "      <td>664.031250</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.634375</td>\n",
              "      <td>0.306250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.496875</td>\n",
              "      <td>0.839951</td>\n",
              "      <td>511.781250</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.915625</td>\n",
              "      <td>0.581250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.762736</td>\n",
              "      <td>760.875000</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.231250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.626578</td>\n",
              "      <td>596.156250</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956250</td>\n",
              "      <td>0.443750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362500</td>\n",
              "      <td>0.945380</td>\n",
              "      <td>524.531250</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.456250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.793750</td>\n",
              "      <td>1.068691</td>\n",
              "      <td>632.687500</td>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.112500</td>\n",
              "      <td>0.618750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.777740</td>\n",
              "      <td>791.250000</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.262500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.325625</td>\n",
              "      <td>0.972308</td>\n",
              "      <td>533.968750</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875625</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.356250</td>\n",
              "      <td>0.878400</td>\n",
              "      <td>492.343750</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.212500</td>\n",
              "      <td>0.928564</td>\n",
              "      <td>731.187500</td>\n",
              "      <td>0.000820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.439375</td>\n",
              "      <td>0.974575</td>\n",
              "      <td>769.781250</td>\n",
              "      <td>0.000737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958125</td>\n",
              "      <td>0.481250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.847500</td>\n",
              "      <td>1.008254</td>\n",
              "      <td>476.781250</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.128750</td>\n",
              "      <td>0.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.239375</td>\n",
              "      <td>0.933214</td>\n",
              "      <td>828.656250</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.751875</td>\n",
              "      <td>0.487500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.534375</td>\n",
              "      <td>0.774391</td>\n",
              "      <td>535.468750</td>\n",
              "      <td>0.000887</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.059375</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.221875</td>\n",
              "      <td>1.022181</td>\n",
              "      <td>667.468750</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.190625</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.528903</td>\n",
              "      <td>511.906250</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.418750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.150000</td>\n",
              "      <td>0.565060</td>\n",
              "      <td>458.125000</td>\n",
              "      <td>0.000963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.337500</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.641250</td>\n",
              "      <td>0.797226</td>\n",
              "      <td>531.000000</td>\n",
              "      <td>0.001142</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.078750</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.356250</td>\n",
              "      <td>0.598702</td>\n",
              "      <td>528.281250</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.456250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.946875</td>\n",
              "      <td>0.272860</td>\n",
              "      <td>632.406250</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.628125</td>\n",
              "      <td>0.318750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.571875</td>\n",
              "      <td>0.669761</td>\n",
              "      <td>506.875000</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.040625</td>\n",
              "      <td>0.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.053125</td>\n",
              "      <td>0.768826</td>\n",
              "      <td>454.281250</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.228125</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.234375</td>\n",
              "      <td>0.249227</td>\n",
              "      <td>275.968750</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.478125</td>\n",
              "      <td>0.756250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.303125</td>\n",
              "      <td>0.578601</td>\n",
              "      <td>641.406250</td>\n",
              "      <td>0.000893</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>0.506250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.434375</td>\n",
              "      <td>1.068006</td>\n",
              "      <td>759.562500</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.903125</td>\n",
              "      <td>0.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>0.825790</td>\n",
              "      <td>388.812500</td>\n",
              "      <td>0.003497</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.384375</td>\n",
              "      <td>0.565887</td>\n",
              "      <td>925.125000</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.865625</td>\n",
              "      <td>0.518750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.434375</td>\n",
              "      <td>0.719660</td>\n",
              "      <td>432.281250</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.803125</td>\n",
              "      <td>0.506250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.637500</td>\n",
              "      <td>0.906595</td>\n",
              "      <td>468.406250</td>\n",
              "      <td>0.001134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.012500</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.061875</td>\n",
              "      <td>1.007064</td>\n",
              "      <td>309.406250</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.180625</td>\n",
              "      <td>0.693750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.012500</td>\n",
              "      <td>1.085515</td>\n",
              "      <td>293.406250</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.018750</td>\n",
              "      <td>0.618750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.668750</td>\n",
              "      <td>0.792407</td>\n",
              "      <td>678.250000</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>0.606250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.709375</td>\n",
              "      <td>0.912909</td>\n",
              "      <td>826.000000</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.171875</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.859375</td>\n",
              "      <td>0.656587</td>\n",
              "      <td>506.406250</td>\n",
              "      <td>0.001246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.184375</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.693750</td>\n",
              "      <td>0.695253</td>\n",
              "      <td>326.218750</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.406250</td>\n",
              "      <td>0.912500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.265625</td>\n",
              "      <td>0.970262</td>\n",
              "      <td>799.781250</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.687968</td>\n",
              "      <td>502.218750</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.559375</td>\n",
              "      <td>0.942992</td>\n",
              "      <td>767.843750</td>\n",
              "      <td>0.001277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.021875</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.001250</td>\n",
              "      <td>0.862032</td>\n",
              "      <td>370.375000</td>\n",
              "      <td>0.006859</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.026250</td>\n",
              "      <td>0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.518750</td>\n",
              "      <td>0.907775</td>\n",
              "      <td>685.593750</td>\n",
              "      <td>0.002221</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.568750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.325000</td>\n",
              "      <td>0.704298</td>\n",
              "      <td>581.281250</td>\n",
              "      <td>0.005574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.612500</td>\n",
              "      <td>0.801672</td>\n",
              "      <td>623.187500</td>\n",
              "      <td>0.004717</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956250</td>\n",
              "      <td>0.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.206250</td>\n",
              "      <td>0.341179</td>\n",
              "      <td>588.812500</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.418750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.765625</td>\n",
              "      <td>0.895082</td>\n",
              "      <td>485.687500</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.071875</td>\n",
              "      <td>0.693750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.684375</td>\n",
              "      <td>0.570960</td>\n",
              "      <td>730.875000</td>\n",
              "      <td>0.003158</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.637500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>1.786875</td>\n",
              "      <td>0.788968</td>\n",
              "      <td>539.406250</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.905625</td>\n",
              "      <td>0.631250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.425000</td>\n",
              "      <td>1.000988</td>\n",
              "      <td>497.500000</td>\n",
              "      <td>0.003008</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.237500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.040625</td>\n",
              "      <td>1.173003</td>\n",
              "      <td>653.125000</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.165625</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.453125</td>\n",
              "      <td>0.763078</td>\n",
              "      <td>572.125000</td>\n",
              "      <td>0.010885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.896875</td>\n",
              "      <td>0.556250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.053125</td>\n",
              "      <td>0.986043</td>\n",
              "      <td>445.625000</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.140625</td>\n",
              "      <td>0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.862500</td>\n",
              "      <td>0.524189</td>\n",
              "      <td>602.250000</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.528125</td>\n",
              "      <td>0.873708</td>\n",
              "      <td>602.562500</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.909375</td>\n",
              "      <td>0.618750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>1.809375</td>\n",
              "      <td>0.672732</td>\n",
              "      <td>388.656250</td>\n",
              "      <td>0.013970</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.115625</td>\n",
              "      <td>0.631250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.340625</td>\n",
              "      <td>0.400986</td>\n",
              "      <td>270.281250</td>\n",
              "      <td>0.006108</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.271875</td>\n",
              "      <td>0.943750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.662500</td>\n",
              "      <td>0.931991</td>\n",
              "      <td>649.375000</td>\n",
              "      <td>0.002835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.209375</td>\n",
              "      <td>1.117439</td>\n",
              "      <td>671.531250</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.909375</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.566390</td>\n",
              "      <td>551.218750</td>\n",
              "      <td>0.010129</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.021875</td>\n",
              "      <td>0.843472</td>\n",
              "      <td>456.062500</td>\n",
              "      <td>0.012298</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.228125</td>\n",
              "      <td>0.731250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.709375</td>\n",
              "      <td>1.002166</td>\n",
              "      <td>803.593750</td>\n",
              "      <td>0.001725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.028125</td>\n",
              "      <td>0.681250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.053125</td>\n",
              "      <td>1.068988</td>\n",
              "      <td>653.468750</td>\n",
              "      <td>0.004090</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.096875</td>\n",
              "      <td>0.706250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.515625</td>\n",
              "      <td>0.878679</td>\n",
              "      <td>779.187500</td>\n",
              "      <td>0.001983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.884375</td>\n",
              "      <td>0.631250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.643750</td>\n",
              "      <td>0.369497</td>\n",
              "      <td>769.093750</td>\n",
              "      <td>0.005212</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.031250</td>\n",
              "      <td>0.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.240625</td>\n",
              "      <td>1.031950</td>\n",
              "      <td>617.187500</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.221875</td>\n",
              "      <td>0.768750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.861354</td>\n",
              "      <td>707.062500</td>\n",
              "      <td>0.012257</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.706250</td>\n",
              "      <td>0.707870</td>\n",
              "      <td>638.031250</td>\n",
              "      <td>0.004701</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.981250</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.537500</td>\n",
              "      <td>1.221314</td>\n",
              "      <td>680.093750</td>\n",
              "      <td>0.002825</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.306250</td>\n",
              "      <td>0.964144</td>\n",
              "      <td>588.187500</td>\n",
              "      <td>0.011327</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.731250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.587500</td>\n",
              "      <td>1.140580</td>\n",
              "      <td>778.593750</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.537500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.971875</td>\n",
              "      <td>0.739033</td>\n",
              "      <td>609.125000</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.196875</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.971875</td>\n",
              "      <td>0.459907</td>\n",
              "      <td>483.968750</td>\n",
              "      <td>0.003220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.146875</td>\n",
              "      <td>0.825000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.525000</td>\n",
              "      <td>0.808033</td>\n",
              "      <td>401.875000</td>\n",
              "      <td>0.004628</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.393750</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.203125</td>\n",
              "      <td>1.056472</td>\n",
              "      <td>378.937500</td>\n",
              "      <td>0.007723</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.190625</td>\n",
              "      <td>0.762500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.748125</td>\n",
              "      <td>0.936744</td>\n",
              "      <td>743.312500</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.066875</td>\n",
              "      <td>0.681250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.265625</td>\n",
              "      <td>0.193841</td>\n",
              "      <td>307.937500</td>\n",
              "      <td>0.010548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.396875</td>\n",
              "      <td>0.868750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.116875</td>\n",
              "      <td>0.707818</td>\n",
              "      <td>422.968750</td>\n",
              "      <td>0.003720</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.148125</td>\n",
              "      <td>0.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.046250</td>\n",
              "      <td>0.712012</td>\n",
              "      <td>524.937500</td>\n",
              "      <td>0.006067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.227500</td>\n",
              "      <td>0.818750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.975000</td>\n",
              "      <td>0.954231</td>\n",
              "      <td>734.125000</td>\n",
              "      <td>0.002089</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.068750</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.078125</td>\n",
              "      <td>0.510265</td>\n",
              "      <td>575.375000</td>\n",
              "      <td>0.002933</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.284375</td>\n",
              "      <td>0.793750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.070000</td>\n",
              "      <td>0.785480</td>\n",
              "      <td>517.562500</td>\n",
              "      <td>0.003760</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.095000</td>\n",
              "      <td>0.725000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.673158</td>\n",
              "      <td>733.968750</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.162500</td>\n",
              "      <td>0.637500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>0.864903</td>\n",
              "      <td>497.000000</td>\n",
              "      <td>0.002806</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.993750</td>\n",
              "      <td>0.831250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.546875</td>\n",
              "      <td>0.652326</td>\n",
              "      <td>372.750000</td>\n",
              "      <td>0.006298</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.378125</td>\n",
              "      <td>0.918750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.325000</td>\n",
              "      <td>0.639712</td>\n",
              "      <td>488.250000</td>\n",
              "      <td>0.009360</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.293750</td>\n",
              "      <td>0.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.471875</td>\n",
              "      <td>0.659809</td>\n",
              "      <td>359.968750</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.321875</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.637500</td>\n",
              "      <td>1.061380</td>\n",
              "      <td>684.125000</td>\n",
              "      <td>0.003006</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.571875</td>\n",
              "      <td>0.664006</td>\n",
              "      <td>560.718750</td>\n",
              "      <td>0.008864</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.240625</td>\n",
              "      <td>0.768750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>2.531250</td>\n",
              "      <td>0.785728</td>\n",
              "      <td>313.593750</td>\n",
              "      <td>0.088903</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.331250</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.990625</td>\n",
              "      <td>1.137555</td>\n",
              "      <td>560.093750</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.096875</td>\n",
              "      <td>0.768750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.611875</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>799.468750</td>\n",
              "      <td>0.002743</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.955625</td>\n",
              "      <td>0.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>1.515625</td>\n",
              "      <td>1.150279</td>\n",
              "      <td>622.843750</td>\n",
              "      <td>0.029404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.268750</td>\n",
              "      <td>0.671632</td>\n",
              "      <td>333.468750</td>\n",
              "      <td>0.010030</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.562500</td>\n",
              "      <td>0.631917</td>\n",
              "      <td>490.656250</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.906250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.165625</td>\n",
              "      <td>0.850123</td>\n",
              "      <td>828.218750</td>\n",
              "      <td>0.003760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.653125</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.653125</td>\n",
              "      <td>0.791572</td>\n",
              "      <td>827.625000</td>\n",
              "      <td>0.002180</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.003125</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.321875</td>\n",
              "      <td>0.962374</td>\n",
              "      <td>445.250000</td>\n",
              "      <td>0.003725</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.034375</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.111875</td>\n",
              "      <td>0.660230</td>\n",
              "      <td>819.843750</td>\n",
              "      <td>0.010496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655625</td>\n",
              "      <td>0.456250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.828125</td>\n",
              "      <td>0.659124</td>\n",
              "      <td>424.406250</td>\n",
              "      <td>0.008260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.084375</td>\n",
              "      <td>0.743750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.465000</td>\n",
              "      <td>0.938254</td>\n",
              "      <td>422.562500</td>\n",
              "      <td>0.005879</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.950625</td>\n",
              "      <td>0.862833</td>\n",
              "      <td>558.218750</td>\n",
              "      <td>0.002039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.194375</td>\n",
              "      <td>0.756250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.165625</td>\n",
              "      <td>0.356837</td>\n",
              "      <td>378.625000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.265625</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.671875</td>\n",
              "      <td>0.861605</td>\n",
              "      <td>840.906250</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.009375</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.578125</td>\n",
              "      <td>0.774297</td>\n",
              "      <td>533.093750</td>\n",
              "      <td>0.006845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.096875</td>\n",
              "      <td>0.452180</td>\n",
              "      <td>266.500000</td>\n",
              "      <td>0.011530</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.234375</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.968750</td>\n",
              "      <td>1.042958</td>\n",
              "      <td>661.406250</td>\n",
              "      <td>0.002716</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.106250</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>0.711492</td>\n",
              "      <td>512.218750</td>\n",
              "      <td>0.031123</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.778750</td>\n",
              "      <td>0.759459</td>\n",
              "      <td>600.781250</td>\n",
              "      <td>0.004884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.085000</td>\n",
              "      <td>0.693750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.031250</td>\n",
              "      <td>0.891295</td>\n",
              "      <td>656.500000</td>\n",
              "      <td>0.002366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.218750</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.111875</td>\n",
              "      <td>0.555440</td>\n",
              "      <td>310.468750</td>\n",
              "      <td>0.007429</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.230625</td>\n",
              "      <td>0.818750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>1.142929</td>\n",
              "      <td>484.125000</td>\n",
              "      <td>0.006147</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.112500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.869375</td>\n",
              "      <td>0.713972</td>\n",
              "      <td>619.312500</td>\n",
              "      <td>0.006464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125625</td>\n",
              "      <td>0.743750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.065625</td>\n",
              "      <td>0.966248</td>\n",
              "      <td>947.343750</td>\n",
              "      <td>0.003129</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.590625</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.268750</td>\n",
              "      <td>0.440748</td>\n",
              "      <td>583.968750</td>\n",
              "      <td>0.002334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.387500</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.071875</td>\n",
              "      <td>0.618060</td>\n",
              "      <td>477.062500</td>\n",
              "      <td>0.004393</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.253125</td>\n",
              "      <td>0.818750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.846875</td>\n",
              "      <td>0.810450</td>\n",
              "      <td>584.687500</td>\n",
              "      <td>0.003732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.121875</td>\n",
              "      <td>0.725000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.737500</td>\n",
              "      <td>0.844327</td>\n",
              "      <td>424.625000</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>0.856250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.468750</td>\n",
              "      <td>0.728729</td>\n",
              "      <td>429.031250</td>\n",
              "      <td>0.005504</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.281250</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>0.462354</td>\n",
              "      <td>669.406250</td>\n",
              "      <td>0.008069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.018750</td>\n",
              "      <td>0.631250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.093750</td>\n",
              "      <td>0.829353</td>\n",
              "      <td>512.781250</td>\n",
              "      <td>0.005605</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.831250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.606250</td>\n",
              "      <td>0.382356</td>\n",
              "      <td>815.718750</td>\n",
              "      <td>0.005639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.031250</td>\n",
              "      <td>0.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>1.437500</td>\n",
              "      <td>0.855304</td>\n",
              "      <td>583.156250</td>\n",
              "      <td>0.019707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.587500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>1.858750</td>\n",
              "      <td>0.579893</td>\n",
              "      <td>246.625000</td>\n",
              "      <td>0.012407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.046250</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.334375</td>\n",
              "      <td>0.655039</td>\n",
              "      <td>317.281250</td>\n",
              "      <td>0.005737</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.278125</td>\n",
              "      <td>0.868750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.993750</td>\n",
              "      <td>0.882413</td>\n",
              "      <td>664.750000</td>\n",
              "      <td>0.003965</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.012500</td>\n",
              "      <td>0.668750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.025000</td>\n",
              "      <td>0.554484</td>\n",
              "      <td>326.406250</td>\n",
              "      <td>0.003288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.137500</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.421875</td>\n",
              "      <td>0.510191</td>\n",
              "      <td>465.281250</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.428125</td>\n",
              "      <td>0.931250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.934375</td>\n",
              "      <td>0.710307</td>\n",
              "      <td>313.718750</td>\n",
              "      <td>0.004430</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.315625</td>\n",
              "      <td>0.931250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.862500</td>\n",
              "      <td>0.788196</td>\n",
              "      <td>615.625000</td>\n",
              "      <td>0.003574</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.656250</td>\n",
              "      <td>0.981138</td>\n",
              "      <td>822.656250</td>\n",
              "      <td>0.002116</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956250</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.159375</td>\n",
              "      <td>0.509165</td>\n",
              "      <td>484.906250</td>\n",
              "      <td>0.003602</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.303125</td>\n",
              "      <td>0.856250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.706250</td>\n",
              "      <td>0.907131</td>\n",
              "      <td>576.500000</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.075000</td>\n",
              "      <td>0.631250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.406250</td>\n",
              "      <td>0.492573</td>\n",
              "      <td>382.000000</td>\n",
              "      <td>0.004517</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.443750</td>\n",
              "      <td>0.837500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.428275</td>\n",
              "      <td>690.812500</td>\n",
              "      <td>0.005654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.878125</td>\n",
              "      <td>1.063955</td>\n",
              "      <td>411.062500</td>\n",
              "      <td>0.004851</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.303125</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.175000</td>\n",
              "      <td>0.833930</td>\n",
              "      <td>742.875000</td>\n",
              "      <td>0.002372</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.112500</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.190000</td>\n",
              "      <td>1.285310</td>\n",
              "      <td>574.687500</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.102500</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.365625</td>\n",
              "      <td>0.851125</td>\n",
              "      <td>549.843750</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.215625</td>\n",
              "      <td>0.837500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.046875</td>\n",
              "      <td>0.754265</td>\n",
              "      <td>569.156250</td>\n",
              "      <td>0.005708</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.165625</td>\n",
              "      <td>0.756250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.659375</td>\n",
              "      <td>0.799002</td>\n",
              "      <td>606.593750</td>\n",
              "      <td>0.003809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.971875</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.446875</td>\n",
              "      <td>0.792064</td>\n",
              "      <td>854.218750</td>\n",
              "      <td>0.002087</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.784375</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.441875</td>\n",
              "      <td>1.014674</td>\n",
              "      <td>451.187500</td>\n",
              "      <td>0.003290</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.235625</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>2.550000</td>\n",
              "      <td>0.787980</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>0.016301</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.331250</td>\n",
              "      <td>0.843750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model and save test dataset\n",
        "model, tokenizer, test_dataset = setup_and_train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My training curves in W&B :\n",
        "\n",
        "![Screeshot](./images/W&B_Train_GRPO.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}